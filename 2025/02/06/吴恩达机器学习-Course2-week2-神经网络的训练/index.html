<!DOCTYPE HTML>
<html lang="en">


<head>
    <meta charset="utf-8">
    <meta name="keywords" content="吴恩达机器学习 Course2 week2 神经网络的训练, 小小舒的爪哇天地">
    <meta name="description" content="吴恩达机器学习 Course2 week2 神经网络的训练1 Tensorflow神经网络 的编译和训练1-1 Tensorflow的实现# compile()函数所有的可选选项及其示例
model.compile(loss=tf.kera">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=no">
    <meta name="renderer" content="webkit|ie-stand|ie-comp">
    <meta name="mobile-web-app-capable" content="yes">
    <meta name="format-detection" content="telephone=no">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
    <meta name="referrer" content="no-referrer-when-downgrade">
    <!-- Global site tag (gtag.js) - Google Analytics -->


    <title>吴恩达机器学习 Course2 week2 神经网络的训练 | 小小舒的爪哇天地</title>
    <link rel="icon" type="image/png" href="/favicon.png">
    


    <!-- bg-cover style     -->



<link rel="stylesheet" type="text/css" href="/libs/awesome/css/all.min.css">
<link rel="stylesheet" type="text/css" href="/libs/materialize/materialize.min.css">
<link rel="stylesheet" type="text/css" href="/libs/aos/aos.css">
<link rel="stylesheet" type="text/css" href="/libs/animate/animate.min.css">
<link rel="stylesheet" type="text/css" href="/libs/lightGallery/css/lightgallery.min.css">
<link rel="stylesheet" type="text/css" href="/css/matery.css">
<link rel="stylesheet" type="text/css" href="/css/my.css">
<link rel="stylesheet" type="text/css" href="/css/dark.css" media="none" onload="if(media!='all')media='all'">




    <link rel="stylesheet" href="/libs/tocbot/tocbot.css">
    <link rel="stylesheet" href="/css/post.css">




    
        <link rel="stylesheet" type="text/css" href="/css/reward.css">
    



    <script src="/libs/jquery/jquery-3.6.0.min.js"></script>

<meta name="generator" content="Hexo 7.3.0">
<style>.github-emoji { position: relative; display: inline-block; width: 1.2em; min-height: 1.2em; overflow: hidden; vertical-align: top; color: transparent; }  .github-emoji > span { position: relative; z-index: 10; }  .github-emoji img, .github-emoji .fancybox { margin: 0 !important; padding: 0 !important; border: none !important; outline: none !important; text-decoration: none !important; user-select: none !important; cursor: auto !important; }  .github-emoji img { height: 1.2em !important; width: 1.2em !important; position: absolute !important; left: 50% !important; top: 50% !important; transform: translate(-50%, -50%) !important; user-select: none !important; cursor: auto !important; } .github-emoji-fallback { color: inherit; } .github-emoji-fallback img { opacity: 0 !important; }</style>
</head>


<body>
    <header class="navbar-fixed">
    <nav id="headNav" class="bg-color nav-transparent">
        <div id="navContainer" class="nav-wrapper container">
            <div class="brand-logo">
                <a href="/" class="waves-effect waves-light">
                    
                    <img src="/medias/logo.png" class="logo-img" alt="LOGO">
                    
                    <span class="logo-span">小小舒的爪哇天地</span>
                </a>
            </div>
            

<a href="#" data-target="mobile-nav" class="sidenav-trigger button-collapse"><i class="fas fa-bars"></i></a>
<ul class="right nav-menu">
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/" class="waves-effect waves-light">
      
      <i class="fas fa-home" style="zoom: 0.6;"></i>
      
      <span>Index</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/tags" class="waves-effect waves-light">
      
      <i class="fas fa-tags" style="zoom: 0.6;"></i>
      
      <span>Tags</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/categories" class="waves-effect waves-light">
      
      <i class="fas fa-bookmark" style="zoom: 0.6;"></i>
      
      <span>Categories</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/archives" class="waves-effect waves-light">
      
      <i class="fas fa-archive" style="zoom: 0.6;"></i>
      
      <span>Archives</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/about" class="waves-effect waves-light">
      
      <i class="fas fa-user-circle" style="zoom: 0.6;"></i>
      
      <span>About</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/contact" class="waves-effect waves-light">
      
      <i class="fas fa-comments" style="zoom: 0.6;"></i>
      
      <span>Contact</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/friends" class="waves-effect waves-light">
      
      <i class="fas fa-address-book" style="zoom: 0.6;"></i>
      
      <span>Friends</span>
    </a>
    
  </li>
  
  <li>
    <a href="#searchModal" class="modal-trigger waves-effect waves-light">
      <i id="searchIcon" class="fas fa-search" title="Search" style="zoom: 0.85;"></i>
    </a>
  </li>
  <li>
    <a href="javascript:;" class="waves-effect waves-light" onclick="switchNightMode()" title="深色/浅色模式" >
      <i id="sum-moon-icon" class="fas fa-sun" style="zoom: 0.85;"></i>
    </a>
  </li>
</ul>


<div id="mobile-nav" class="side-nav sidenav">

    <div class="mobile-head bg-color">
        
        <img src="/medias/logo.png" class="logo-img circle responsive-img">
        
        <div class="logo-name">小小舒的爪哇天地</div>
        <div class="logo-desc">
            
            Life is coding, I will debug it.
            
        </div>
    </div>

    <ul class="menu-list mobile-menu-list">
        
        <li class="m-nav-item">
	  
		<a href="/" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-home"></i>
			
			Index
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/tags" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-tags"></i>
			
			Tags
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/categories" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-bookmark"></i>
			
			Categories
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/archives" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-archive"></i>
			
			Archives
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/about" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-user-circle"></i>
			
			About
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/contact" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-comments"></i>
			
			Contact
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/friends" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-address-book"></i>
			
			Friends
		</a>
          
        </li>
        
        
        <li><div class="divider"></div></li>
        <li>
            <a href="https://github.com/blinkfox/hexo-theme-matery" class="waves-effect waves-light" target="_blank">
                <i class="fab fa-github-square fa-fw"></i>Fork Me
            </a>
        </li>
        
    </ul>
</div>


        </div>

        
            <style>
    .nav-transparent .github-corner {
        display: none !important;
    }

    .github-corner {
        position: absolute;
        z-index: 10;
        top: 0;
        right: 0;
        border: 0;
        transform: scale(1.1);
    }

    .github-corner svg {
        color: #0f9d58;
        fill: #fff;
        height: 64px;
        width: 64px;
    }

    .github-corner:hover .octo-arm {
        animation: a 0.56s ease-in-out;
    }

    .github-corner .octo-arm {
        animation: none;
    }

    @keyframes a {
        0%,
        to {
            transform: rotate(0);
        }
        20%,
        60% {
            transform: rotate(-25deg);
        }
        40%,
        80% {
            transform: rotate(10deg);
        }
    }
</style>

<a href="https://github.com/blinkfox/hexo-theme-matery" class="github-corner tooltipped hide-on-med-and-down" target="_blank"
   data-tooltip="Fork Me" data-position="left" data-delay="50">
    <svg viewBox="0 0 250 250" aria-hidden="true">
        <path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path>
        <path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2"
              fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path>
        <path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z"
              fill="currentColor" class="octo-body"></path>
    </svg>
</a>
        
    </nav>

</header>

    



<div class="bg-cover pd-header post-cover" style="background-image: url('/medias/featureimages/12.jpg')">
    <div class="container" style="right: 0px;left: 0px;">
        <div class="row">
            <div class="col s12 m12 l12">
                <div class="brand">
                    <h1 class="description center-align post-title">吴恩达机器学习 Course2 week2 神经网络的训练</h1>
                </div>
            </div>
        </div>
    </div>
</div>




<main class="post-container content">

    
    <div class="row">
    <div id="main-content" class="col s12 m12 l9">
        <!-- 文章内容详情 -->
<div id="artDetail">
    <div class="card">
        <div class="card-content article-info">
            <div class="row tag-cate">
                <div class="col s7">
                    
                    <div class="article-tag">
                        
                            <a href="/tags/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/">
                                <span class="chip bg-color">人工智能</span>
                            </a>
                        
                            <a href="/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/">
                                <span class="chip bg-color">机器学习</span>
                            </a>
                        
                            <a href="/tags/deep-learning/">
                                <span class="chip bg-color">deep learning</span>
                            </a>
                        
                            <a href="/tags/tensorflow/">
                                <span class="chip bg-color">tensorflow</span>
                            </a>
                        
                            <a href="/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/">
                                <span class="chip bg-color">深度学习</span>
                            </a>
                        
                            <a href="/tags/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/">
                                <span class="chip bg-color">神经网络</span>
                            </a>
                        
                    </div>
                    
                </div>
                <div class="col s5 right-align">
                    
                    <div class="post-cate">
                        <i class="fas fa-bookmark fa-fw icon-category"></i>
                        
                            <a href="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/" class="post-category">
                                机器学习
                            </a>
                        
                    </div>
                    
                </div>
            </div>

            <div class="post-info">
                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-minus fa-fw"></i>Publish Date:&nbsp;&nbsp;
                    2025-02-06
                </div>
                

                

                
                <div class="info-break-policy">
                    <i class="far fa-file-word fa-fw"></i>Word Count:&nbsp;&nbsp;
                    7k
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-clock fa-fw"></i>Read Times:&nbsp;&nbsp;
                    25 Min
                </div>
                

                
                    <div id="busuanzi_container_page_pv" class="info-break-policy">
                        <i class="far fa-eye fa-fw"></i>Read Count:&nbsp;&nbsp;
                        <span id="busuanzi_value_page_pv"></span>
                    </div>
				
            </div>
        </div>
        <hr class="clearfix">

        
        <!-- 是否加载使用自带的 prismjs. -->
        <link rel="stylesheet" href="/libs/prism/prism.min.css">
        

        

        <div class="card-content article-card-content">
            <div id="articleContent">
                <h1 id="吴恩达机器学习-Course2-week2-神经网络的训练"><a href="#吴恩达机器学习-Course2-week2-神经网络的训练" class="headerlink" title="吴恩达机器学习 Course2 week2 神经网络的训练"></a>吴恩达机器学习 Course2 week2 神经网络的训练</h1><h2 id="1-Tensorflow神经网络-的编译和训练"><a href="#1-Tensorflow神经网络-的编译和训练" class="headerlink" title="1 Tensorflow神经网络 的编译和训练"></a>1 Tensorflow神经网络 的编译和训练</h2><h3 id="1-1-Tensorflow的实现"><a href="#1-1-Tensorflow的实现" class="headerlink" title="1-1 Tensorflow的实现"></a>1-1 Tensorflow的实现</h3><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token comment"># compile()函数所有的可选选项及其示例</span>
model<span class="token punctuation">.</span><span class="token builtin">compile</span><span class="token punctuation">(</span>loss<span class="token operator">=</span>tf<span class="token punctuation">.</span>keras<span class="token punctuation">.</span>losses<span class="token punctuation">.</span>BinaryCrossentropy<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
              optimizer<span class="token operator">=</span>tf<span class="token punctuation">.</span>keras<span class="token punctuation">.</span>optimizers<span class="token punctuation">.</span>Adam<span class="token punctuation">(</span>learning_rate<span class="token operator">=</span><span class="token number">0.001</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
              metrics<span class="token operator">=</span><span class="token string">'accuracy'</span>
<span class="token punctuation">)</span>
<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<ol>
<li><p>编译<code>compile()</code>：输入参数有“损失函数<code>loss</code>”、“优化器<code>optimizer</code>”、“评估指标<code>metrics</code>”。主要考虑前两项。</p>
<ul>
<li><p>“损失函数loss”：决定了神经网络的代价函数。在“训练”的某次迭代结束后，利用输出层的输出结果与真实目标值之间的差异计算神经网络的代价。进而可以通过反向传播更新参数。</p>
</li>
<li><p>“优化器optimizer”：则是“梯度下降法”的升级版，可以选择性能更强大、收敛速度更快的迭代算法。</p>
</li>
<li><p>“评估指标metrics”：和“训练”本身没有关系，和损失函数没有关系。只是在“训练”的单次迭代结束后，衡量一下所有训练集的推理结果与真实值之间的差异。loss也有此作用，但是不直观；metrics可以选择更加直观的指标，比如metrics=’accuracy’可以计算“推理正确的训练样本”的百分比。</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token comment"># compile()函数所有的可选选项及其示例</span>
model<span class="token punctuation">.</span><span class="token builtin">compile</span><span class="token punctuation">(</span>loss<span class="token operator">=</span>tf<span class="token punctuation">.</span>keras<span class="token punctuation">.</span>losses<span class="token punctuation">.</span>BinaryCrossentropy<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
              optimizer<span class="token operator">=</span>tf<span class="token punctuation">.</span>keras<span class="token punctuation">.</span>optimizers<span class="token punctuation">.</span>Adam<span class="token punctuation">(</span>learning_rate<span class="token operator">=</span><span class="token number">0.001</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
              metrics<span class="token operator">=</span><span class="token string">'accuracy'</span>
<span class="token punctuation">)</span>
<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre></li>
</ul>
</li>
<li><p>训练<code>fit()</code>：有非常多的指标可以设置，但我们现在仅关心“数据集”、“迭代次数<code>epchos</code>”即可(下面代码示例的前三项)。注意每次迭代都会使用到所有的训练集样本，若样本太多，程序会自动将数据分批。并且，运行fit()函数后，会自动打印输出训练过程。</p>
<pre class="line-numbers language-none"><code class="language-none"># fit()函数所有的可选选项及其示例
model.fit(
    x=None,                # 输入数据
    y=None,                # 标签
    epochs=1,              # 训练轮数
    batch_size=None,       # 指定进行梯度下降时每个批次包含的样本数
    verbose=1,             # 控制训练过程中的日志输出，0：不输出日志，1：输出进度条记录，2：每个epoch输出一行记录
    callbacks=None,        # 在训练过程中调用的回调函数列表
    validation_split=0.0,  # 用于验证的训练数据的比例
    validation_data=None,  # 用于验证的数据，可以是输入数据和标签的元组
    shuffle=True,          # 是否在每个epoch之前随机打乱输入数据
    class_weight=None,     # 类别权重
    sample_weight=None,    # 样本权重
    initial_epoch=0,       # 开始训练的epoch值
    steps_per_epoch=None,  # 每个epoch包含的步数，当为None时，将自动计算
    validation_steps=None, # 在每个epoch结束时执行验证的步数，当为None时，将自动计算
    validation_batch_size=None,  # 用于验证的批次大小
    validation_freq=1,     # 仅在`validation_data` 的某些训练轮上进行验证
    max_queue_size=10,     # 生成器队列的最大尺寸
    workers=1,             # 使用的生成器工作进程数
    use_multiprocessing=False,  # 是否使用多进程生成器
    **kwargs
)
# 运行fit()函数后，会自动打印输出训练过程，下面为单次迭代的输出示例
Epoch 1/40
157/157 [==============================] - 1s 1ms/step - loss: 1.5179 - accuracy: 0.5406
<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<h3 id="主要参数-by-deepseek"><a href="#主要参数-by-deepseek" class="headerlink" title="主要参数(by deepseek)"></a><strong>主要参数(by deepseek)</strong></h3><table>
<thead>
<tr>
<th align="left">参数</th>
<th align="left">类型/默认值</th>
<th align="left">说明</th>
</tr>
</thead>
<tbody><tr>
<td align="left"><strong><code>x</code></strong></td>
<td align="left">输入数据</td>
<td align="left">训练数据的特征（可以是 NumPy 数组、TensorFlow Dataset、生成器等）。</td>
</tr>
<tr>
<td align="left"><strong><code>y</code></strong></td>
<td align="left">标签数据</td>
<td align="left">训练数据的标签（与 <code>x</code> 对应）。如果 <code>x</code> 是 Dataset，可省略。</td>
</tr>
<tr>
<td align="left"><strong><code>epochs</code></strong></td>
<td align="left">int, 默认 1</td>
<td align="left">训练的总轮次（完整遍历训练数据的次数）。</td>
</tr>
<tr>
<td align="left"><strong><code>batch_size</code></strong></td>
<td align="left">int, 默认 32</td>
<td align="left">每个批次的样本数。如果数据是 Dataset 或生成器，可忽略。</td>
</tr>
<tr>
<td align="left"><strong><code>verbose</code></strong></td>
<td align="left">0/1/2, 默认 1</td>
<td align="left">日志显示模式： - <code>0</code>: 静默模式 - <code>1</code>: 进度条 - <code>2</code>: 每轮一行输出。</td>
</tr>
<tr>
<td align="left"><strong><code>callbacks</code></strong></td>
<td align="left">list, 默认 <code>[]</code></td>
<td align="left">回调函数列表（如 <code>EarlyStopping</code>, <code>ModelCheckpoint</code> 等）。</td>
</tr>
<tr>
<td align="left"><strong><code>validation_split</code></strong></td>
<td align="left">float (0~1), 默认 0</td>
<td align="left">从训练数据中划分一部分作为验证数据的比例（不能与 <code>validation_data</code> 同时使用）。</td>
</tr>
<tr>
<td align="left"><strong><code>validation_data</code></strong></td>
<td align="left">数据集或元组</td>
<td align="left">验证数据（可以是 <code>(x_val, y_val)</code> 或 Dataset）。</td>
</tr>
<tr>
<td align="left"><strong><code>shuffle</code></strong></td>
<td align="left">bool, 默认 True</td>
<td align="left">是否在每个 epoch 前打乱训练数据顺序（对 Dataset 无效，需提前定义）。</td>
</tr>
<tr>
<td align="left"><strong><code>class_weight</code></strong></td>
<td align="left">dict, 默认 None</td>
<td align="left">类别权重（用于不平衡分类问题，如 <code>{0: 1.0, 1: 0.5}</code>）。</td>
</tr>
<tr>
<td align="left"><strong><code>sample_weight</code></strong></td>
<td align="left">array-like, 默认 None</td>
<td align="left">样本权重（调整每个样本在损失函数中的权重）。</td>
</tr>
<tr>
<td align="left"><strong><code>initial_epoch</code></strong></td>
<td align="left">int, 默认 0</td>
<td align="left">从指定 epoch 开始训练（用于恢复训练）。</td>
</tr>
<tr>
<td align="left"><strong><code>steps_per_epoch</code></strong></td>
<td align="left">int, 默认 None</td>
<td align="left">每个 epoch 的批次数量。若为 None，自动根据数据量计算。</td>
</tr>
<tr>
<td align="left"><strong><code>validation_steps</code></strong></td>
<td align="left">int, 默认 None</td>
<td align="left">验证集的批次数量（仅当 <code>validation_data</code> 是生成器时需指定）。</td>
</tr>
<tr>
<td align="left"><strong><code>validation_batch_size</code></strong></td>
<td align="left">int, 默认 None</td>
<td align="left">验证集的批次大小。</td>
</tr>
<tr>
<td align="left"><strong><code>validation_freq</code></strong></td>
<td align="left">int/list, 默认 1</td>
<td align="left">验证频率（如 <code>2</code> 表示每 2 个 epoch 验证一次）。</td>
</tr>
<tr>
<td align="left"><strong><code>max_queue_size</code></strong></td>
<td align="left">int, 默认 10</td>
<td align="left">生成器队列的最大大小（多进程数据加载时使用）。</td>
</tr>
<tr>
<td align="left"><strong><code>workers</code></strong></td>
<td align="left">int, 默认 1</td>
<td align="left">生成器数据加载的进程数。</td>
</tr>
<tr>
<td align="left"><strong><code>use_multiprocessing</code></strong></td>
<td align="left">bool, 默认 False</td>
<td align="left">是否使用多进程加载生成器数据。</td>
</tr>
</tbody></table>
<blockquote>
<p>官方文档：<a target="_blank" rel="noopener" href="https://www.tensorflow.org/api_docs/python/tf/keras/Model#fit">https://www.tensorflow.org/api_docs/python/tf/keras/Model#fit</a></p>
</blockquote>
<p>熟悉了上面的选项之后，回到简化的“手写数字识别”问题，其训练代码如下，主要看“编译<code>model.compile()</code>”和“训练<code>model.fit()</code>”：</p>
<p><img src="http://img-md-js.linjsblog.top/img/202501281424420.png" alt="img"></p>
</li>
</ol>
<blockquote>
<ol>
<li>定义神经网络。定义神经网络的层数、每层神经元数量、激活函数。和之前相同。</li>
<li>编译神经网络。关键在于确定损失函数，由于是二元分类问题所以选取了“二元交叉熵损失函数”。</li>
<li>训练神经网络。<code>X,Y</code>为训练集、<code>epochs</code>为迭代次数，也就是“梯度下降法”的迭代次数，每次迭代都会使用全部训练集的数据。</li>
</ol>
</blockquote>
<h3 id="1-2-模型训练细节"><a href="#1-2-模型训练细节" class="headerlink" title="1-2 模型训练细节"></a>1-2 模型训练细节</h3><p><strong>损失函数和代价函数的公式：</strong></p>
<p><img src="http://img-md-js.linjsblog.top/img/202502031726897.png" alt="image-20250203172601756"></p>
<p>第一步创建model:</p>
<p><img src="http://img-md-js.linjsblog.top/img/202502031731152.png" alt="image-20250203173157064"></p>
<p>第二步：决定指定用什么损失函数、成本函数来训练神经网络：</p>
<p>对于手写数字分类，图像要么是0，要么是1，损失函数实际与逻辑回归损失函数相同，在统计学上被称作交叉熵损失函数（<strong>binary cross entropy</strong>），所以“complie” 所配置的损失函数是<code>loss=BinaryCrossentropy()</code>，而“二元”只是强调输出为二元分类，所以称之为“<strong>二元交叉熵损失函数</strong>”</p>
<p>在代码实现中，Keras库最初是独立的数学函数库，后来被TensorFlow收录，所以TensorFlow使用Keras库来定义损失函数。这也是最初的代码中，从keras导入损失函数的原因。</p>
<p>当然上述是对“分类问题”的代码，如果想编译“<strong>回归问题</strong>”，可以采用下面的代码(注意修改损失函数):</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token comment"># 回归问题中，使用“平方差损失函数”编译模型</span>
<span class="token keyword">from</span> tensorflow<span class="token punctuation">.</span>keras<span class="token punctuation">.</span>losses <span class="token keyword">import</span> MeanSquareError
model<span class="token punctuation">.</span><span class="token builtin">compile</span><span class="token punctuation">(</span>loss <span class="token operator">=</span> MeanSquareError<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre>

<p>$$<br>\text{Loss Function: } \quad L(f(\vec{x}), y) = -y \log(f(\vec{x})) - (1 - y) \log(1 - f(\vec{x}))<br>\\<br>\text{Cost Function: } \quad<br>\begin{aligned}<br>&amp; J(\mathbf{W}, \mathbf{B}) = \frac{1}{m} \sum_{i=1}^m L(f(\vec{x}), y), \\<br>&amp; \mathbf{W} = [\mathbf{W}^{[1]}, \mathbf{W}^{[2]}, \mathbf{W}^{[3]}], \\<br>&amp; \mathbf{B} = [\mathbf{\tilde{b}}^{[1]}, \mathbf{\tilde{b}}^{[2]}, \mathbf{\tilde{b}}^{[3]}].<br>\end{aligned}<br>$$</p>
<p>面已经介绍了损失函数的数学形式和代码。现在还有最后一点就是在迭代“训练”中，怎么求解代价函数的偏导。显然“训练”的过程就是最小化代价函数，比如使用“梯度下降”，那么每一次迭代都要计算代价函数对每一层每个神经元的每个参数的偏导。这工作量想想就惊人！更别说神经网络很难求出显式的偏导表达式。所以实际上，神经网络的“训练”使用“反向传播**(back propogation**)”来进行迭代，可以大大节省计算量。TensorFlow将上述“反向传播”寻找最低点的过程全部封装在model.fit()函数中，并迭代设定好的次数epochs</p>
<h2 id="2-其他激活函数"><a href="#2-其他激活函数" class="headerlink" title="2 其他激活函数"></a>2 其他激活函数</h2><h3 id="2-1-Sigmoid激活函数的替代方案"><a href="#2-1-Sigmoid激活函数的替代方案" class="headerlink" title="2-1 Sigmoid激活函数的替代方案"></a>2-1 Sigmoid激活函数的替代方案</h3><p>前一直使用Sigmiod函数作为隐藏层和输出层所有神经元的激活函数。但Sigmoid函数显然也有其局限性</p>
<p><img src="http://img-md-js.linjsblog.top/img/202502031856454.png" alt="img"></p>
<p>比如上面的“需求预测”问题，我们最开始假设隐藏层输出的有T恤的“心理预期价格”、“了解程度”、“产品质量”，但实际上这些指标并不一定都是二元的（为0-1之间的小数字），比如“认可度”可以有“不了解”、“一般了解”、“极度了解”、“完全传播开来”等。</p>
<p>于是我们不妨将“认可度”的范围扩展为到所有“非负数”，也就是从0到非常大的数字：ReLu函数（Rectified Linear Unit, 修正线性单元）：g(z) = max(0,z)</p>
<p>下面是三项常用的激活函数：</p>
<p><img src="http://img-md-js.linjsblog.top/img/202502031928927.png" alt="img"></p>
<ol>
<li>线性激活函数：g(z)=z, 人们也会称之为“没有使用任何激活函数”。</li>
<li>Sigmoid函数：$g(z) = \frac{1}{1 + e^{-x}}$ .</li>
<li>ReLU函数: g(z) = max(0,z)</li>
<li>Softmax函数：“第三节”讨论多分类问题时进行介绍</li>
</ol>
<h3 id="2-2-如何选择激活函数"><a href="#2-2-如何选择激活函数" class="headerlink" title="2-2 如何选择激活函数"></a>2-2 如何选择激活函数</h3><p>那该如何选择激活函数呢？首先我们从<strong>输出层</strong>开始。<strong>输出层的激活函数通常取决于“目标值”</strong>，比如<strong>二元分类问题</strong>就使用Sigmoid函数、如果预测股票涨跌的回归问题就使用线性激活函数(因为有正有负)、如果是“预测房价”这样的回归问题就使用ReLU函数(因为房价非负)。而对于<strong>隐藏层</strong>来说，<strong>若无特殊原因，所有隐藏层的神经元都应选择ReLU函数</strong>。最早人们都默认使用Sigmoid函数，但是现在逐渐演变成默认使用ReLU函数，主要有以下几个原因：</p>
<ol>
<li>ReLU函数形式更简单、计算更快。</li>
<li>ReLU仅在负数域平坦，而Sigmoid函数在正负两侧都平坦。而平坦的区域越大，会导致代价函数平坦的区域越大，“梯度下降”等算法训练模型的速度就越慢。</li>
</ol>
<p><strong>总结：“输出层”按照“目标值”取值范围选取，“隐藏层”默认全部采用ReLU函数(如下图)。</strong></p>
<p><img src="http://img-md-js.linjsblog.top/img/202502032047059.png" alt="img"></p>
<p>对于大多数情况、大多数应用来说，上述介绍的几个激活函数已经够用了。当然还有其他激活函数，比如Tanh函数、Leaky ReLU函数、Swish函数等。每隔几年，研究人员都会提出新的激活函数，这些激活函数在某些方面的性能确实会更好。想了解的话可以自行查阅。<a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/172254089">https://zhuanlan.zhihu.com/p/172254089</a></p>
<h3 id="2-3-为什么需要激活函数"><a href="#2-3-为什么需要激活函数" class="headerlink" title="2-3 为什么需要激活函数"></a>2-3 为什么需要激活函数</h3><p>既然ReLU函数比Sigmoid函数计算更快，那能不能默认使用更简洁的“线性激活函数”呢？换句话说，能不能不使用激活函数呢？显然是不行的。由于“<strong>线性函数的线性组合还是线性函数</strong>”，若只使用线性激活函数，整个神经网络就会退化成“线性回归”。所以 <strong>尽量不在隐藏层使用线性激活函数</strong>。使用其他的非线性函数，比如ReLU函数，只要有足够多的神经元，通过调整参数就可以拟合出任意的曲线，进而实现神经网络想要的拟合效果。</p>
<p>我们举个简单的例子展示线性激活函数的局限性：</p>
<p><img src="http://img-md-js.linjsblog.top/img/202502032210015.png" alt="image-20250203221039890"></p>
<p>In general case:</p>
<p><img src="http://img-md-js.linjsblog.top/img/202502032215205.png" alt="image-20250203221534110"></p>
<p>使用线性激活函数的神经网络无法容纳比线性回归更复杂的模型</p>
<h3 id="DeepSeek-对激活函数作用的总结"><a href="#DeepSeek-对激活函数作用的总结" class="headerlink" title="DeepSeek 对激活函数作用的总结"></a>DeepSeek 对激活函数作用的总结</h3><p>激活函数是神经网络中的核心组件之一，其作用可以概括为以下几个方面：</p>
<hr>
<p><strong>1. 引入非线性</strong></p>
<ul>
<li><strong>核心作用</strong>：如果没有激活函数，神经网络的所有层都只是线性变换的叠加（相当于一个线性回归模型），无法解决非线性问题（如异或问题、图像分类等）。</li>
<li><strong>示例</strong>：假设网络有两层线性变换 ( y = W_2(W_1x + b_1) + b_2 )，合并后仍为线性变换 ( y = (W_2W_1)x + (W_2b_1 + b_2) )，无法学习复杂模式。</li>
<li><strong>激活函数的作用</strong>：通过非线性函数（如 ReLU、Sigmoid、Tanh）对每层的输出进行变换，使网络能够逼近任意复杂的函数。</li>
</ul>
<hr>
<p><strong>2. 控制输出范围</strong></p>
<ul>
<li><strong>根据任务需求调整输出</strong>：<ul>
<li><strong>Sigmoid</strong>：将输出压缩到 ( (0,1) )，适用于二分类问题的概率输出。</li>
<li><strong>Tanh</strong>：输出范围为 ( (-1,1) )，适合需要中心化输出的场景。</li>
<li><strong>Softmax</strong>：多分类问题中，将输出转化为概率分布（和为1）。</li>
<li><strong>ReLU</strong>：输出范围为 ( [0, +\infty) )，适合隐藏层，保留特征的强度。</li>
</ul>
</li>
</ul>
<hr>
<p><strong>3. 梯度传递与训练稳定性</strong></p>
<ul>
<li><strong>梯度消失/爆炸问题</strong>：<ul>
<li>Sigmoid 和 Tanh 的导数在输入较大时会趋近于零（梯度消失），导致深层网络难以训练。</li>
<li>ReLU 及其变体（如 Leaky ReLU、ELU）在正区间的导数为1，缓解梯度消失问题，更适合深层网络。</li>
</ul>
</li>
<li><strong>死亡神经元问题</strong>：<ul>
<li>ReLU 在输入为负时梯度为零，可能导致部分神经元永久失效（可通过 Leaky ReLU 或参数化 ReLU 缓解）。</li>
</ul>
</li>
</ul>
<hr>
<p><strong>4. 稀疏性激活</strong></p>
<ul>
<li><strong>ReLU 的稀疏性</strong>：当输入为负时，ReLU 输出零，使部分神经元处于非激活状态。这种稀疏性减少了参数依赖性，提升计算效率，同时可能增强模型的泛化能力（类似生物神经元的“选择性激活”）。</li>
</ul>
<hr>
<p><strong>常见激活函数对比</strong></p>
<table>
<thead>
<tr>
<th>激活函数</th>
<th>公式</th>
<th>优点</th>
<th>缺点</th>
<th>适用场景</th>
</tr>
</thead>
<tbody><tr>
<td><strong>Sigmoid</strong></td>
<td>$ \frac{1}{1+e^{-x}} $</td>
<td>输出概率，平滑可导</td>
<td>梯度消失，非零均值</td>
<td>二分类输出层</td>
</tr>
<tr>
<td><strong>Tanh</strong></td>
<td>$ \frac{e^x - e^{-x}}{e^x + e^{-x}} $</td>
<td>零均值，输出范围更大</td>
<td>梯度消失</td>
<td>隐藏层或需要中心化输出</td>
</tr>
<tr>
<td><strong>ReLU</strong></td>
<td>$ \max(0, x) $</td>
<td>计算高效，缓解梯度消失</td>
<td>死亡神经元，负区间无响应</td>
<td>隐藏层（最常用）</td>
</tr>
<tr>
<td><strong>Leaky ReLU</strong></td>
<td>$ \max(\alpha x, x) $</td>
<td>缓解死亡神经元问题</td>
<td>需人工设置 ( \alpha )</td>
<td>深层网络隐藏层</td>
</tr>
<tr>
<td><strong>Softmax</strong></td>
<td>$ \frac{e^{x_i}}{\sum_j e^{x_j}} $</td>
<td>输出概率分布</td>
<td>仅用于多分类输出层</td>
<td>多分类输出层</td>
</tr>
</tbody></table>
<hr>
<p><strong>选择激活函数的建议</strong></p>
<ol>
<li><strong>隐藏层</strong>：优先使用 <strong>ReLU</strong> 或其变体（如 Leaky ReLU、Swish），计算高效且缓解梯度消失。</li>
<li><strong>输出层</strong>：<ul>
<li>二分类：Sigmoid。</li>
<li>多分类：Softmax。</li>
<li>回归任务：线性激活（无激活函数）或根据输出范围调整。</li>
</ul>
</li>
<li><strong>特殊场景</strong>：对梯度敏感的任务（如生成对抗网络）可尝试 Tanh。</li>
</ol>
<hr>
<p><strong>总结</strong></p>
<p>激活函数通过引入非线性、控制输出范围、调节梯度传递和增强稀疏性，使神经网络能够适应复杂的数据模式。其选择直接影响模型的训练速度、性能和泛化能力，需结合具体任务和网络结构权衡。</p>
<h2 id="3-多分类问题-Softmax"><a href="#3-多分类问题-Softmax" class="headerlink" title="3 多分类问题 &amp; Softmax"></a>3 多分类问题 &amp; Softmax</h2><p>在第一节中，由于“手写数字识别”已经被我们简化成只识别数字1和数字0，所以使用了“二元交叉熵损失函数<code>loss=BinaryCrossentropy()</code>”，那如果要识别全部的数字0~数字9，又该如何设置损失函数呢？下面就来介绍。</p>
<h3 id="3-1-多分类问题"><a href="#3-1-多分类问题" class="headerlink" title="3-1 多分类问题"></a>3-1 多分类问题</h3><p>显然，要识别全部的数字0~数字9，就需要将二元分类问题进行推广。于是，分类输出的目标值有多个可能的问题，便称为“多分类问题(multiclass classfication problem)”。比如“手写数字识别”要分类10个数字、“肿瘤检测”要分类多种恶化类型、流水线产品检测不同类型的缺陷等。</p>
<blockquote>
<p>注：<strong>聚类</strong>是无监督学习，神经网络自行分类；<strong>多分类问题</strong>是有监督学习，只不过是类别多了。</p>
</blockquote>
<p><img src="http://img-md-js.linjsblog.top/img/202502032326746.png" alt="从二元分类推广到多分类"></p>
<h3 id="3-2-Softmax"><a href="#3-2-Softmax" class="headerlink" title="3-2 Softmax"></a>3-2 Softmax</h3><p>下面是Softmax函数的定义，也就是 $g(z)$的定义：<br><img src="http://img-md-js.linjsblog.top/img/202502032328138.png" alt="img"></p>
<blockquote>
<p>j 为单层神经网络内的神经元索引；k 也为神经元索引，但其主要目的是将本层内所有神经元求和。<br>$a_j$：当前层第 j 个神经元的输出。</p>
<p>注1：尽管参数不完全一致，但 N = 2  时，“Softmax回归”会退化成“逻辑回归”。<br>注2：Softmax回归使用指数，不仅可以保证概率非负，同时也可以扩大不同值之间的差异。<br>注3：多分类问题所有可能输出的概率之和为1。</p>
</blockquote>
<p>于是类似于“逻辑回归”的“二元交叉熵(Binary Crossen tropy)损失函数”，“Softmax回归”的<strong>损失函数</strong>为“<strong>稀疏分类交叉熵</strong>(<strong>Sparse Categorical Crossen tropy</strong>)”。同样也是，推理结果越接近真实结果，损失越小：</p>
<p><img src="http://img-md-js.linjsblog.top/img/202502032340519.png" alt="img"></p>
<h3 id="3-3-神经网络的softmax输出"><a href="#3-3-神经网络的softmax输出" class="headerlink" title="3-3 神经网络的softmax输出"></a>3-3 神经网络的softmax输出</h3><p>显然，要创建解决多分类问题的神经网络，只需要更改输出层激活函数为“Softmax函数”、损失函数为“稀疏分类交叉熵”即可，代码如下：</p>
<p><img src="http://img-md-js.linjsblog.top/img/202502051749293.png" alt="img"></p>
<p>注意到，Softmax层，也被称为“Softmax激活函数”，和之前的激活函数都不同。因为Softmax函数的输出$a_j$ 不只取决于当前的输入$z_j$, 而是取决于所有的输入$ z_1,…,z_N$, 所以Softmax层并不能逐个计算神经元的输出，而是需要“<strong>同时计算</strong>”该层所有神经元的输出。</p>
<h3 id="3-4-softmax-的改进实现"><a href="#3-4-softmax-的改进实现" class="headerlink" title="3-4 softmax 的改进实现"></a>3-4 softmax 的改进实现</h3><p>虽然上述代码规定好了损失函数，<strong>但实际上并不采用上述代码</strong>。因为采用上面的代码，会要求TensorFlow保留损失函数计算的中间结果，$a_j, j = 1,…,N$。但实际上，多计算一个变量就会引入更多的舍入误差，尤其是“Sigmoid函数$\frac{1}{1+e^{-z}}$”, “Softmax函数$\frac{e^{z_j}}{\sum_{k=1}^{N} e^{z_k} }$ “ 的计算结果中，其总会有些值非常小，进而使得计算精度不足导致 <strong>舍入误差</strong>（IEEE754）. 为了消除这部分的舍入误差，我们可以令TensorFlow不要再计算中间结果$z$,而是直接将 $z$的表达式代入到损失函数中。这样<strong>TensorFlow会先化简损失函数表达式（重排列），再进行计算，从而减少一步</strong>的舍入误差：</p>
<p><img src="http://img-md-js.linjsblog.top/img/202502052015295.png" alt="img"></p>
<p><img src="http://img-md-js.linjsblog.top/img/202502052121785.png" alt="img"></p>
<p>如上图，现在我们仅使用线性激活函数，也就是最后一层仅计算z1~z10, 然后在损失函数处捕获整个损失计算，所以我们有了from_logits参数</p>
<p>使用数值稳定的数学公式（如Log-Sum-Exp技巧），避免中间步骤的数值问题。</p>
<p><img src="http://img-md-js.linjsblog.top/img/202502052209026.png" alt="image-20250205220932935"></p>
<p>分子分母同乘以max(z)可以减少e^x指数的大小，从而避免浮点数上溢或下溢</p>
<p><img src="http://img-md-js.linjsblog.top/img/202502052212092.png" alt="image-20250205221245991"></p>
<p><img src="http://img-md-js.linjsblog.top/img/202502052214252.png" alt="image-20250205221423148"></p>
<p><img src="http://img-md-js.linjsblog.top/img/202502052226596.png" alt="image-20250205222609492"></p>
<blockquote>
<p>具体数学细节可看：课后资源: C2_W2_SoftMax 中的 Numerical Stability (optional)</p>
</blockquote>
<p><strong>总结</strong></p>
<ul>
<li>**何时使用线性激活 + <code>from_logits=True</code>**：当损失函数是交叉熵且需要数值稳定性和高效计算时。</li>
<li><strong>何时保留Softmax激活</strong>：如果需要在模型推理时直接输出概率（例如，部署时），或使用不兼容<code>from_logits</code>的自定义损失函数。</li>
</ul>
<h3 id="3-5-多标签问题"><a href="#3-5-多标签问题" class="headerlink" title="3-5 多标签问题"></a>3-5 多标签问题</h3><p>最后，“多分类问题(multi-classfication problem)”和“多标签问题(multi-label problem)”非常容易混淆，本小节就是来区分一下这两个定义。“多标签分类”是一个输入，多个不同类型的分类。所以，“多标签问题”可以看成是多个“二元分类”的组合。比如下面的“多标签问题”就是由3个不同的“二元分类”组成的：</p>
<p><img src="http://img-md-js.linjsblog.top/img/202502052254586.png" alt="img"></p>
<p>直观上，我们可能会想到针对不同的标签分类，创建各自独立的的神经网络，比如上图就创建三个独立的神经网络，但显然这看起来不聪明，所以实际上会<strong>创建一个神经网络同时解决这三个二元分类</strong>。创建网络时只要注意将最后的输出层调整为三个Sigmoid神经元即可。</p>
<p>下一节来介绍更加高级的神经网络概念，包括比“梯度下降”更好的迭代算法。</p>
<h2 id="4-更加高级的神经网络概念"><a href="#4-更加高级的神经网络概念" class="headerlink" title="4 更加高级的神经网络概念"></a>4 更加高级的神经网络概念</h2><h3 id="4-1-梯度下降法的改进：Adam算法"><a href="#4-1-梯度下降法的改进：Adam算法" class="headerlink" title="4-1 梯度下降法的改进：Adam算法"></a>4-1 梯度下降法的改进：Adam算法</h3><p>“梯度下降”广泛应用于机器学习算法中，如线性回归、逻辑回归、神经网络早期实现等，但是还有其他性能更好的最下滑代价函数的算法。比如“**Adam算法(Adaptive Moment estimation, 自适应矩估计)**”就可以自动调整“梯度下降”学习率 α 的大小，从而加快“梯度下降”的收敛速度。下面是其算法逻辑和代码示例</p>
<ol>
<li>“Adam算法”并不只使用同一个学习率α，而是 <strong>针对每个参数都定义一个</strong> $\alpha_j$</li>
<li>如果参数一直向同一个方向前进，就逐步增大该参数的学习率；若每次方向都不一样(振荡)，就逐步减小学习率。</li>
<li>Adam算法”还需要一个参数来控制每个参数的学习率的增大或减小的速度——全局学习率(下面设置为$10^{-3}$ )</li>
</ol>
<p><img src="http://img-md-js.linjsblog.top/img/202502052338651.png" alt="img"></p>
<h3 id="4-2-其他的网络层模型"><a href="#4-2-其他的网络层模型" class="headerlink" title="4-2 其他的网络层模型"></a>4-2 其他的网络层模型</h3><p>目前为止学习到的所有神经网络都是“**密集层类型(dense layer type)<strong>”，也就是<u>层内的每一个神经元都会得到上一层的所有输入特征</u>。虽然“密集层类型”的神经网络功能很强大，但是其计算量很大。于是，Yann LeCun 最早提出“</strong>卷积层(convolution layer)**”，并将其应用到计算机视觉领域。“卷积层”中，<u>每个神经元只关心输入图像的某个区域</u>。如下左图中，对于输入图像，每个神经元只关心某个小区域(按照颜色对应)。“卷积层”的优点如下：</p>
<ol>
<li>加快计算。</li>
<li>需要的训练集可以更小，并且也不容易“过拟合”。（Week3会更加详细的介绍“过拟合”）</li>
</ol>
<p><img src="http://img-md-js.linjsblog.top/img/202502052356238.png" alt="img"></p>
<blockquote>
<p>上图给出了“心电图监测”问题：根据心电图(electrocardiogram, EKG/ECG)判断是否有心脏病。</p>
<ul>
<li>输入特征：长度为100的心电图信号。</li>
<li>输出：有心脏病的概率。</li>
</ul>
</blockquote>
<p>上右图便给出了“心电图监测”问题(本小节开始的说明)的卷积神经网络示意图，每个神经元只能查看一个小窗口（如第一个神经元查看x1-x20）;下一层也可以是一个卷积层，第1个单元只会查看$a_1^{[1]}到a_5^{[1]}$,第2个单元只会查看$a_3^{[1]}到a_7^{[1]}$, 第3个单元只会查看$a_5^{[1]}到a_9^{[1]}$, 然后将第二层$a^{[2]}$ 输入到sigmoid单元，以便对是否存在心脏病进行二元分类。</p>
<p>显然，改变每个神经元查看的窗口大小，每一个有多少神经元，有效的选择这些参数，可以构建比“密集层类型”更加有效的神经网络。</p>
<p>除了“卷积层”之外，当然还有其他的神经网络层类型，将不同类型的“层”结合在一起，组成更加强大的神经网络：</p>
<blockquote>
<ol>
<li><p>全连接层（Fully Connected Layer）：全连接层是最简单的神经网络层，其中每个神经元与上一层的所有神经元相连接。</p>
</li>
<li><p>卷积层（Convolutional Layer）：卷积层用于处理图像和其他二维数据，通过卷积操作提取图像的局部特征。</p>
</li>
<li><p>池化层（Pooling Layer）：池化层通常与卷积层结合使用，用于减小特征图的空间尺寸，提高计算效率，并减少参数量。</p>
</li>
<li><p>循环神经网络层（Recurrent Neural Network Layer）：RNN层用于处理序列数据，具有记忆性，能够捕捉时间上的依赖关系。</p>
</li>
<li><p>长短时记忆网络层（Long Short-Term Memory Layer，LSTM）：LSTM是一种特殊的循环神经网络层，具有更强大的记忆性，适用于处理长序列依赖关系。</p>
<p>……</p>
</li>
</ol>
</blockquote>
<h2 id="5-反向传播"><a href="#5-反向传播" class="headerlink" title="5 反向传播"></a>5 反向传播</h2><p>“反向传播”是“自动微分(auto-diff)算法”的一种。接下来介绍TensorFlow如何使用“反向传播”，计算神经网络的代价函数对所有参数的偏导。</p>
<h3 id="5-1-计算图和导数"><a href="#5-1-计算图和导数" class="headerlink" title="5-1 计算图和导数"></a>5-1 计算图和导数</h3><p>显然，由于神经网络可以创建的相当庞大，所以很难显式的写出偏导表达式。此时，我们求解代价函数偏导的思路就转成，<strong>求解代价函数在该点切线的斜率，也就是使用很小的步长来近似当前点的切线斜率</strong>。但是神经网络通常又有很多层，于是对于每个神经元的每个参数都通过这种方式，直接迭代一次神经网络求解对一个参数的偏导，显然也不现实。于是，我们先通过“<strong>计算图</strong>(Computation Graph)”来研究一下神经网络的计算流程，找找灵感，比如下面对于单神经元网络的代价函数计算：</p>
<p><img src="http://img-md-js.linjsblog.top/img/202502060055205.png" alt="img"></p>
<p>也就是，将整体的计算过程拆成一步一步的，就组成了“计算图”。从左到右，求解当前点的代价函数大小很简单。但注意到，如果我们想要求解代价函数的表达式时，还可以根据上述“计算图”写出求导的“链式法则(chain rule)”！！而且“链式法则”的顺序正好是从右向左的！！由于越靠右的节点也会被更多的参数共用，<strong>于是反向传播一次，便可以把依次把路径上的每一个参数的偏导都求解出来</strong>。而不是针对每个参数，都额外增加一点，通过从左到右计算代价函数的变化率来求得相应参数的偏导。于是，若“计算图”总共有 N 个节点、P 个输入参数，要计算所有函数偏导：</p>
<blockquote>
<ul>
<li>反向传播：只需大约 N + P 个步骤。</li>
<li>针对每个参数求切线斜率：大约 N × P  个步骤。</li>
</ul>
<p>总结：在“计算图”中使用“链式法则”可以大大加快神经网络的训练速度！！<br>           <strong>反向传播就是从左到右计算代价函数，然后从右向左计算所有参数的偏导</strong>。</p>
</blockquote>
<h3 id="5-2-大型神经网络案例"><a href="#5-2-大型神经网络案例" class="headerlink" title="5-2 大型神经网络案例"></a>5-2 大型神经网络案例</h3><p>在关于反向传播的最后一节中，让我们来看一下如何将反向传播的思想应用到大型神经网络中。</p>
<p><img src="http://img-md-js.linjsblog.top/img/202502060129087.png" alt="img"></p>
<p>先“前向传播”计算神经网络中所有神经元的取值，然后一次“反向传播”遍历走完所有节点，即可计算出神经网络的代价函数对每个神经元的每个参数的偏导。显然，此时“计算图”实际上就相当于神经网络。</p>
<p>在许多年前，在Tensorflow和pytorch等框架兴起之前，研究人员过去必须手动使用微积分计算他们想到训练的神经网络的导数，因此在现代程序框架中，你可以指定一个forward prop 并让他为你处理back prop; 很多年以前，研究人员手写神经网络，手动使用微积分计算导数，然后神经网络执行他们在纸上费力推导出来的一堆方程，以实现反向传播，多亏了计算图和这些进行导数计算的技术，如autodiff, 用于自动微分，这种研究人员手动使用微积分求导的过程is no longer done. 所以随着神经网络的成熟，这些工作量下降了，这对很多人来说是令人鼓舞的。</p>
<h2 id="6-Exercise：多分类的神经网络手写数字识别"><a href="#6-Exercise：多分类的神经网络手写数字识别" class="headerlink" title="6 Exercise：多分类的神经网络手写数字识别"></a>6 Exercise：多分类的神经网络手写数字识别</h2><blockquote>
<p>可以在课程资料中的C2_W2_Assignment中进行练习</p>
</blockquote>
<pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token comment"># 导入头文件</span>
<span class="token keyword">import</span> numpy <span class="token keyword">as</span> np
<span class="token keyword">import</span> tensorflow <span class="token keyword">as</span> tf
<span class="token keyword">from</span> keras<span class="token punctuation">.</span>models <span class="token keyword">import</span> Sequential
<span class="token keyword">from</span> keras<span class="token punctuation">.</span>layers <span class="token keyword">import</span> Dense
<span class="token keyword">from</span> keras<span class="token punctuation">.</span>activations <span class="token keyword">import</span> linear<span class="token punctuation">,</span> relu<span class="token punctuation">,</span> sigmoid
<span class="token keyword">import</span> matplotlib<span class="token punctuation">.</span>pyplot <span class="token keyword">as</span> plt

plt<span class="token punctuation">.</span>style<span class="token punctuation">.</span>use<span class="token punctuation">(</span><span class="token string">'./deeplearning.mplstyle'</span><span class="token punctuation">)</span>
<span class="token keyword">import</span> logging

logging<span class="token punctuation">.</span>getLogger<span class="token punctuation">(</span><span class="token string">"tensorflow"</span><span class="token punctuation">)</span><span class="token punctuation">.</span>setLevel<span class="token punctuation">(</span>logging<span class="token punctuation">.</span>ERROR<span class="token punctuation">)</span>
tf<span class="token punctuation">.</span>autograph<span class="token punctuation">.</span>set_verbosity<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span>

<span class="token comment"># 加载训练集：5000张手写体图片，每张图片大小20x20</span>
X <span class="token operator">=</span> np<span class="token punctuation">.</span>load<span class="token punctuation">(</span><span class="token string">"data/X.npy"</span><span class="token punctuation">)</span>  <span class="token comment"># 5000x400</span>
y <span class="token operator">=</span> np<span class="token punctuation">.</span>load<span class="token punctuation">(</span><span class="token string">"data/y.npy"</span><span class="token punctuation">)</span>  <span class="token comment"># 5000x1</span>

<span class="token comment"># 定义神经网络</span>
model <span class="token operator">=</span> Sequential<span class="token punctuation">(</span>
    <span class="token punctuation">[</span>
        tf<span class="token punctuation">.</span>keras<span class="token punctuation">.</span>Input<span class="token punctuation">(</span>shape<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">400</span><span class="token punctuation">,</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span>  <span class="token comment"># 输入特征的长度</span>
        Dense<span class="token punctuation">(</span>units<span class="token operator">=</span><span class="token number">25</span><span class="token punctuation">,</span> activation<span class="token operator">=</span><span class="token string">'relu'</span><span class="token punctuation">,</span> name<span class="token operator">=</span><span class="token string">'layer1'</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
        Dense<span class="token punctuation">(</span>units<span class="token operator">=</span><span class="token number">15</span><span class="token punctuation">,</span> activation<span class="token operator">=</span><span class="token string">'relu'</span><span class="token punctuation">,</span> name<span class="token operator">=</span><span class="token string">'layer2'</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
        Dense<span class="token punctuation">(</span>units<span class="token operator">=</span><span class="token number">10</span><span class="token punctuation">,</span> activation<span class="token operator">=</span><span class="token string">'linear'</span><span class="token punctuation">,</span> name<span class="token operator">=</span><span class="token string">'layer3'</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
    <span class="token punctuation">]</span><span class="token punctuation">,</span> name<span class="token operator">=</span><span class="token string">"my_model"</span>
<span class="token punctuation">)</span>

<span class="token comment"># 编译模型</span>
model<span class="token punctuation">.</span><span class="token builtin">compile</span><span class="token punctuation">(</span>
    loss<span class="token operator">=</span>tf<span class="token punctuation">.</span>keras<span class="token punctuation">.</span>losses<span class="token punctuation">.</span>SparseCategoricalCrossentropy<span class="token punctuation">(</span>from_logits<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
    optimizer<span class="token operator">=</span>tf<span class="token punctuation">.</span>keras<span class="token punctuation">.</span>optimizers<span class="token punctuation">.</span>Adam<span class="token punctuation">(</span>learning_rate<span class="token operator">=</span><span class="token number">0.001</span><span class="token punctuation">)</span>
<span class="token punctuation">)</span>

<span class="token comment"># 训练模型</span>
history <span class="token operator">=</span> model<span class="token punctuation">.</span>fit<span class="token punctuation">(</span>X<span class="token punctuation">,</span> y<span class="token punctuation">,</span> epochs<span class="token operator">=</span><span class="token number">40</span><span class="token punctuation">)</span>

<span class="token comment"># 预测结果</span>
image_new <span class="token operator">=</span> X<span class="token punctuation">[</span><span class="token number">1015</span><span class="token punctuation">]</span>
prediction <span class="token operator">=</span> model<span class="token punctuation">.</span>predict<span class="token punctuation">(</span>image_new<span class="token punctuation">.</span>reshape<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">400</span><span class="token punctuation">)</span><span class="token punctuation">)</span>  <span class="token comment"># prediction</span>
yhat <span class="token operator">=</span> np<span class="token punctuation">.</span>argmax<span class="token punctuation">(</span>prediction<span class="token punctuation">)</span>
prediction_p <span class="token operator">=</span> tf<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>softmax<span class="token punctuation">(</span>prediction<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f" Largest Prediction index: </span><span class="token interpolation"><span class="token punctuation">{</span>yhat<span class="token punctuation">}</span></span><span class="token string">"</span></span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f"The Probability of Largest index: </span><span class="token interpolation"><span class="token punctuation">{</span>prediction_p<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span> yhat<span class="token punctuation">]</span><span class="token punctuation">:</span><span class="token format-spec">0.2f</span><span class="token punctuation">}</span></span><span class="token string">"</span></span><span class="token punctuation">)</span>

<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<p><img src="http://img-md-js.linjsblog.top/img/202502061354997.png" alt="“定义神经网络”后的神经网络参数"></p>
<p><img src="http://img-md-js.linjsblog.top/img/202502061355110.png" alt="“预测”单个图片"></p>
<p><img src="http://img-md-js.linjsblog.top/img/202502061404113.png" alt="预测错误汇总"></p>

                
            </div>
            <hr/>

            

    <div class="reprint" id="reprint-statement">
        
            <div class="reprint__author">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-user">
                        Author:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="/about" rel="external nofollow noreferrer">qwq小小舒</a>
                </span>
            </div>
            <div class="reprint__type">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-link">
                        Link:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="https://js6288.github.io/2025/02/06/%E5%90%B4%E6%81%A9%E8%BE%BE%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0-Course2-week2-%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E7%9A%84%E8%AE%AD%E7%BB%83/">https://js6288.github.io/2025/02/06/%E5%90%B4%E6%81%A9%E8%BE%BE%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0-Course2-week2-%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E7%9A%84%E8%AE%AD%E7%BB%83/</a>
                </span>
            </div>
            <div class="reprint__notice">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-copyright">
                        Reprint policy:
                    </i>
                </span>
                <span class="reprint-info">
                    All articles in this blog are used except for special statements
                    <a href="https://creativecommons.org/licenses/by/4.0/deed.zh" rel="external nofollow noreferrer" target="_blank">CC BY 4.0</a>
                    reprint policy. If reproduced, please indicate source
                    <a href="/about" target="_blank">qwq小小舒</a>
                    !
                </span>
            </div>
        
    </div>

    <script async defer>
      document.addEventListener("copy", function (e) {
        let toastHTML = '<span>Copied successfully, please follow the reprint policy of this article</span><button class="btn-flat toast-action" onclick="navToReprintStatement()" style="font-size: smaller">more</a>';
        M.toast({html: toastHTML})
      });

      function navToReprintStatement() {
        $("html, body").animate({scrollTop: $("#reprint-statement").offset().top - 80}, 800);
      }
    </script>



            <div class="tag_share" style="display: block;">
                <div class="post-meta__tag-list" style="display: inline-block;">
                    
                        <div class="article-tag">
                            
                                <a href="/tags/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/">
                                    <span class="chip bg-color">人工智能</span>
                                </a>
                            
                                <a href="/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/">
                                    <span class="chip bg-color">机器学习</span>
                                </a>
                            
                                <a href="/tags/deep-learning/">
                                    <span class="chip bg-color">deep learning</span>
                                </a>
                            
                                <a href="/tags/tensorflow/">
                                    <span class="chip bg-color">tensorflow</span>
                                </a>
                            
                                <a href="/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/">
                                    <span class="chip bg-color">深度学习</span>
                                </a>
                            
                                <a href="/tags/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/">
                                    <span class="chip bg-color">神经网络</span>
                                </a>
                            
                        </div>
                    
                </div>
                <div class="post_share" style="zoom: 80%; width: fit-content; display: inline-block; float: right; margin: -0.15rem 0;">
                    <link rel="stylesheet" type="text/css" href="/libs/share/css/share.min.css">
<div id="article-share">

    
    <div class="social-share" data-sites="twitter,facebook,google,qq,qzone,wechat,weibo,douban,linkedin" data-wechat-qrcode-helper="<p>微信扫一扫即可分享！</p>"></div>
    <script src="/libs/share/js/social-share.min.js"></script>
    

    

</div>

                </div>
            </div>
            
                <div id="reward">
    <a href="#rewardModal" class="reward-link modal-trigger btn-floating btn-medium waves-effect waves-light red">赏</a>

    <!-- Modal Structure -->
    <div id="rewardModal" class="modal">
        <div class="modal-content">
            <a class="close modal-close"><i class="fas fa-times"></i></a>
            <h4 class="reward-title">你的赏识是我前进的动力</h4>
            <div class="reward-content">
                <div class="reward-tabs">
                    <ul class="tabs row">
                        <li class="tab col s6 alipay-tab waves-effect waves-light"><a href="#alipay">支付宝</a></li>
                        <li class="tab col s6 wechat-tab waves-effect waves-light"><a href="#wechat">微 信</a></li>
                    </ul>
                    <div id="alipay">
                        <img src="/medias/reward/alipay1.jpg" class="reward-img" alt="支付宝打赏二维码">
                    </div>
                    <div id="wechat">
                        <img src="/medias/reward/wechat.jpg" class="reward-img" alt="微信打赏二维码">
                    </div>
                </div>
            </div>
        </div>
    </div>
</div>

<script>
    $(function () {
        $('.tabs').tabs();
    });
</script>

            
        </div>
    </div>

    

    

    

    

    

    

    

    

    

<article id="prenext-posts" class="prev-next articles">
    <div class="row article-row">
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge left-badge text-color">
                <i class="fas fa-chevron-left"></i>&nbsp;Previous</div>
            <div class="card">
                <a href="/2025/02/09/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%90%B4%E6%81%A9%E8%BE%BEcourse2week3/">
                    <div class="card-image">
                        
                        
                        <img src="/medias/featureimages/2.jpg" class="responsive-img" alt="吴恩达机器学习 Course2 week3 使用机器学习的建议">
                        
                        <span class="card-title">吴恩达机器学习 Course2 week3 使用机器学习的建议</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            
                        
                    </div>
                    <div class="publish-info">
                        <span class="publish-date">
                            <i class="far fa-clock fa-fw icon-date"></i>2025-02-09
                        </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/" class="post-category">
                                    机器学习
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/tags/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/">
                        <span class="chip bg-color">人工智能</span>
                    </a>
                    
                    <a href="/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/">
                        <span class="chip bg-color">机器学习</span>
                    </a>
                    
                    <a href="/tags/deep-learning/">
                        <span class="chip bg-color">deep learning</span>
                    </a>
                    
                    <a href="/tags/tensorflow/">
                        <span class="chip bg-color">tensorflow</span>
                    </a>
                    
                    <a href="/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/">
                        <span class="chip bg-color">深度学习</span>
                    </a>
                    
                    <a href="/tags/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/">
                        <span class="chip bg-color">神经网络</span>
                    </a>
                    
                    <a href="/tags/%E7%B2%BE%E7%A1%AE%E5%BA%A6%E5%92%8C%E5%8F%AC%E5%9B%9E%E7%8E%87/">
                        <span class="chip bg-color">精确度和召回率</span>
                    </a>
                    
                    <a href="/tags/%E5%81%8F%E5%B7%AE%E5%92%8C%E6%96%B9%E5%B7%AE/">
                        <span class="chip bg-color">偏差和方差</span>
                    </a>
                    
                    <a href="/tags/%E5%80%BE%E6%96%9C%E6%95%B0%E6%8D%AE%E9%9B%86/">
                        <span class="chip bg-color">倾斜数据集</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge right-badge text-color">
                Next&nbsp;<i class="fas fa-chevron-right"></i>
            </div>
            <div class="card">
                <a href="/2025/01/28/%E5%90%B4%E6%81%A9%E8%BE%BE%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0-course2-week1-%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/">
                    <div class="card-image">
                        
                        
                        <img src="/medias/featureimages/23.jpg" class="responsive-img" alt="吴恩达机器学习 Course2 week1 神经网络">
                        
                        <span class="card-title">吴恩达机器学习 Course2 week1 神经网络</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            
                        
                    </div>
                    <div class="publish-info">
                            <span class="publish-date">
                                <i class="far fa-clock fa-fw icon-date"></i>2025-01-28
                            </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/" class="post-category">
                                    机器学习
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/tags/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/">
                        <span class="chip bg-color">人工智能</span>
                    </a>
                    
                    <a href="/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/">
                        <span class="chip bg-color">机器学习</span>
                    </a>
                    
                    <a href="/tags/deep-learning/">
                        <span class="chip bg-color">deep learning</span>
                    </a>
                    
                    <a href="/tags/tensorflow/">
                        <span class="chip bg-color">tensorflow</span>
                    </a>
                    
                    <a href="/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/">
                        <span class="chip bg-color">深度学习</span>
                    </a>
                    
                    <a href="/tags/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/">
                        <span class="chip bg-color">神经网络</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
    </div>
</article>

</div>



<!-- 代码块功能依赖 -->
<script type="text/javascript" src="/libs/codeBlock/codeBlockFuction.js"></script>


  <!-- 是否加载使用自带的 prismjs. -->
  <script type="text/javascript" src="/libs/prism/prism.min.js"></script>


<!-- 代码语言 -->

<script type="text/javascript" src="/libs/codeBlock/codeLang.js"></script>


<!-- 代码块复制 -->

<script type="text/javascript" src="/libs/codeBlock/codeCopy.js"></script>


<!-- 代码块收缩 -->

<script type="text/javascript" src="/libs/codeBlock/codeShrink.js"></script>



    </div>
    <div id="toc-aside" class="expanded col l3 hide-on-med-and-down">
        <div class="toc-widget card" style="background-color: white;">
            <div class="toc-title"><i class="far fa-list-alt"></i>&nbsp;&nbsp;TOC</div>
            <div id="toc-content"></div>
        </div>
    </div>
</div>

<!-- TOC 悬浮按钮. -->

<div id="floating-toc-btn" class="hide-on-med-and-down">
    <a class="btn-floating btn-large bg-color">
        <i class="fas fa-list-ul"></i>
    </a>
</div>


<script src="/libs/tocbot/tocbot.min.js"></script>
<script>
    $(function () {
        tocbot.init({
            tocSelector: '#toc-content',
            contentSelector: '#articleContent',
            headingsOffset: -($(window).height() * 0.4 - 45),
            collapseDepth: Number('0'),
            headingSelector: 'h2, h3, h4'
        });

        // Set scroll toc fixed.
        let tocHeight = parseInt($(window).height() * 0.4 - 64);
        let $tocWidget = $('.toc-widget');
        $(window).scroll(function () {
            let scroll = $(window).scrollTop();
            /* add post toc fixed. */
            if (scroll > tocHeight) {
                $tocWidget.addClass('toc-fixed');
            } else {
                $tocWidget.removeClass('toc-fixed');
            }
        });

        
        /* 修复文章卡片 div 的宽度. */
        let fixPostCardWidth = function (srcId, targetId) {
            let srcDiv = $('#' + srcId);
            if (srcDiv.length === 0) {
                return;
            }

            let w = srcDiv.width();
            if (w >= 450) {
                w = w + 21;
            } else if (w >= 350 && w < 450) {
                w = w + 18;
            } else if (w >= 300 && w < 350) {
                w = w + 16;
            } else {
                w = w + 14;
            }
            $('#' + targetId).width(w);
        };

        // 切换TOC目录展开收缩的相关操作.
        const expandedClass = 'expanded';
        let $tocAside = $('#toc-aside');
        let $mainContent = $('#main-content');
        $('#floating-toc-btn .btn-floating').click(function () {
            if ($tocAside.hasClass(expandedClass)) {
                $tocAside.removeClass(expandedClass).hide();
                $mainContent.removeClass('l9');
            } else {
                $tocAside.addClass(expandedClass).show();
                $mainContent.addClass('l9');
            }
            fixPostCardWidth('artDetail', 'prenext-posts');
        });
        
    });
</script>

    

</main>


<script src="https://cdn.bootcss.com/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
<script>
    MathJax.Hub.Config({
        tex2jax: {
            inlineMath: [['$', '$'], ['\\(', '\\)']],
            displayMath: [['$$','$$'], ['\\[','\\]']],
            processEscapes: true,
            skipTags: ['script', 'noscript', 'style', 'textarea', 'pre']
        },
        TeX: {
            extensions: ["AMSmath.js", "AMSsymbols.js"] // 手动加载 AMS 扩展
        }
    });
</script>



    <footer class="page-footer bg-color">
    

    <div class="container row center-align"
         style="margin-bottom: 0px !important;">
        <div class="col s12 m8 l8 copy-right">
            Copyright&nbsp;&copy;
            
                <span id="year">2019-2025</span>
            
            <a href="/about" target="_blank">qwq小小舒</a>
            |&nbsp;Powered by&nbsp;<a href="https://hexo.io/" target="_blank">Hexo</a>
            |&nbsp;Theme&nbsp;<a href="https://github.com/blinkfox/hexo-theme-matery" target="_blank">Matery</a>
            
            <br>
            
            
            
                
            
            
                <span id="busuanzi_container_site_pv">
                &nbsp;|&nbsp;<i class="far fa-eye"></i>&nbsp;Total visits:&nbsp;
                    <span id="busuanzi_value_site_pv" class="white-color"></span>
            </span>
            
            
                <span id="busuanzi_container_site_uv">
                &nbsp;|&nbsp;<i class="fas fa-users"></i>&nbsp;Total visitors:&nbsp;
                    <span id="busuanzi_value_site_uv" class="white-color"></span>
            </span>
            
            <br>

            <!-- 运行天数提醒. -->
            
            <br>
            
        </div>
        <div class="col s12 m4 l4 social-link social-statis">
    <a href="https://github.com/js6288" class="tooltipped" target="_blank" data-tooltip="访问我的GitHub" data-position="top" data-delay="50">
        <i class="fab fa-github"></i>
    </a>



    <a href="mailto:linjingshu6288@163.com" class="tooltipped" target="_blank" data-tooltip="邮件联系我" data-position="top" data-delay="50">
        <i class="fas fa-envelope-open"></i>
    </a>







    <a href="tencent://AddContact/?fromId=50&fromSubId=1&subcmd=all&uin=1279897306" class="tooltipped" target="_blank" data-tooltip="QQ联系我: 1279897306" data-position="top" data-delay="50">
        <i class="fab fa-qq"></i>
    </a>







    <a href="/atom.xml" class="tooltipped" target="_blank" data-tooltip="RSS 订阅" data-position="top" data-delay="50">
        <i class="fas fa-rss"></i>
    </a>

</div>
    </div>
</footer>

<div class="progress-bar"></div>


    <!-- 搜索遮罩框 -->
<div id="searchModal" class="modal">
    <div class="modal-content">
        <div class="search-header">
            <span class="title"><i class="fas fa-search"></i>&nbsp;&nbsp;Search</span>
            <input type="search" id="searchInput" name="s" placeholder="Please enter a search keyword"
                   class="search-input">
        </div>
        <div id="searchResult"></div>
    </div>
</div>

<script type="text/javascript">
$(function () {
    var searchFunc = function (path, search_id, content_id) {
        'use strict';
        $.ajax({
            url: path,
            dataType: "xml",
            success: function (xmlResponse) {
                // get the contents from search data
                var datas = $("entry", xmlResponse).map(function () {
                    return {
                        title: $("title", this).text(),
                        content: $("content", this).text(),
                        url: $("url", this).text()
                    };
                }).get();
                var $input = document.getElementById(search_id);
                var $resultContent = document.getElementById(content_id);
                $input.addEventListener('input', function () {
                    var str = '<ul class=\"search-result-list\">';
                    var keywords = this.value.trim().toLowerCase().split(/[\s\-]+/);
                    $resultContent.innerHTML = "";
                    if (this.value.trim().length <= 0) {
                        return;
                    }
                    // perform local searching
                    datas.forEach(function (data) {
                        var isMatch = true;
                        var data_title = data.title.trim().toLowerCase();
                        var data_content = data.content.trim().replace(/<[^>]+>/g, "").toLowerCase();
                        var data_url = data.url;
                        data_url = data_url.indexOf('/') === 0 ? data.url : '/' + data_url;
                        var index_title = -1;
                        var index_content = -1;
                        var first_occur = -1;
                        // only match artiles with not empty titles and contents
                        if (data_title !== '' && data_content !== '') {
                            keywords.forEach(function (keyword, i) {
                                index_title = data_title.indexOf(keyword);
                                index_content = data_content.indexOf(keyword);
                                if (index_title < 0 && index_content < 0) {
                                    isMatch = false;
                                } else {
                                    if (index_content < 0) {
                                        index_content = 0;
                                    }
                                    if (i === 0) {
                                        first_occur = index_content;
                                    }
                                }
                            });
                        }
                        // show search results
                        if (isMatch) {
                            str += "<li><a href='" + data_url + "' class='search-result-title'>" + data_title + "</a>";
                            var content = data.content.trim().replace(/<[^>]+>/g, "");
                            if (first_occur >= 0) {
                                // cut out 100 characters
                                var start = first_occur - 20;
                                var end = first_occur + 80;
                                if (start < 0) {
                                    start = 0;
                                }
                                if (start === 0) {
                                    end = 100;
                                }
                                if (end > content.length) {
                                    end = content.length;
                                }
                                var match_content = content.substr(start, end);
                                // highlight all keywords
                                keywords.forEach(function (keyword) {
                                    var regS = new RegExp(keyword, "gi");
                                    match_content = match_content.replace(regS, "<em class=\"search-keyword\">" + keyword + "</em>");
                                });

                                str += "<p class=\"search-result\">" + match_content + "...</p>"
                            }
                            str += "</li>";
                        }
                    });
                    str += "</ul>";
                    $resultContent.innerHTML = str;
                });
            }
        });
    };

    searchFunc('/search.xml', 'searchInput', 'searchResult');
});
</script>

    <!-- 白天和黑夜主题 -->
<div class="stars-con">
    <div id="stars"></div>
    <div id="stars2"></div>
    <div id="stars3"></div>  
</div>

<script>
    function switchNightMode() {
        $('<div class="Cuteen_DarkSky"><div class="Cuteen_DarkPlanet"></div></div>').appendTo($('body')),
        setTimeout(function () {
            $('body').hasClass('DarkMode') 
            ? ($('body').removeClass('DarkMode'), localStorage.setItem('isDark', '0'), $('#sum-moon-icon').removeClass("fa-sun").addClass('fa-moon')) 
            : ($('body').addClass('DarkMode'), localStorage.setItem('isDark', '1'), $('#sum-moon-icon').addClass("fa-sun").removeClass('fa-moon')),
            
            setTimeout(function () {
            $('.Cuteen_DarkSky').fadeOut(1e3, function () {
                $(this).remove()
            })
            }, 2e3)
        })
    }
</script>

    <!-- 回到顶部按钮 -->
<div id="backTop" class="top-scroll">
    <a class="btn-floating btn-large waves-effect waves-light" href="#!">
        <i class="fas fa-arrow-up"></i>
    </a>
</div>


    <script src="/libs/materialize/materialize.min.js"></script>
    <script src="/libs/masonry/masonry.pkgd.min.js"></script>
    <script src="/libs/aos/aos.js"></script>
    <script src="/libs/scrollprogress/scrollProgress.min.js"></script>
    <script src="/libs/lightGallery/js/lightgallery-all.min.js"></script>
    <script src="/js/matery.js"></script>

    

    
    
    

    <!-- 雪花特效 -->
    

    <!-- 鼠标星星特效 -->
    

     
        <script src="https://ssl.captcha.qq.com/TCaptcha.js"></script>
        <script src="/libs/others/TencentCaptcha.js"></script>
        <button id="TencentCaptcha" data-appid="xxxxxxxxxx" data-cbfn="callback" type="button" hidden></button>
    

    <!-- Baidu Analytics -->

    <!-- Baidu Push -->

<script>
    (function () {
        var bp = document.createElement('script');
        var curProtocol = window.location.protocol.split(':')[0];
        if (curProtocol === 'https') {
            bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';
        } else {
            bp.src = 'http://push.zhanzhang.baidu.com/push.js';
        }
        var s = document.getElementsByTagName("script")[0];
        s.parentNode.insertBefore(bp, s);
    })();
</script>

    
    <script src="/libs/others/clicklove.js" async="async"></script>
    
    
    <script async src="/libs/others/busuanzi.pure.mini.js"></script>
    

    

    

    <!--腾讯兔小巢-->
    
    

    

    

    
    <script src="/libs/instantpage/instantpage.js" type="module"></script>
    

</body>

</html>
