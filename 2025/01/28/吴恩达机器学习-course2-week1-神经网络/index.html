<!DOCTYPE HTML>
<html lang="en">


<head>
    <meta charset="utf-8">
    <meta name="keywords" content="吴恩达机器学习 Course2 week1 神经网络, 小小舒的爪哇天地">
    <meta name="description" content="吴恩达机器学习 Course2 week1 神经网络1 神经网络概述1-1 关于Course 2Course2会学习“神经网络”(也被称为“深度学习”)、决策树等算法，这些是最强大、最广泛使用的机器学习算法之一。另外也会介绍构建机器学习系统">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=no">
    <meta name="renderer" content="webkit|ie-stand|ie-comp">
    <meta name="mobile-web-app-capable" content="yes">
    <meta name="format-detection" content="telephone=no">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
    <meta name="referrer" content="no-referrer-when-downgrade">
    <!-- Global site tag (gtag.js) - Google Analytics -->


    <title>吴恩达机器学习 Course2 week1 神经网络 | 小小舒的爪哇天地</title>
    <link rel="icon" type="image/png" href="/favicon.png">
    


    <!-- bg-cover style     -->



<link rel="stylesheet" type="text/css" href="/libs/awesome/css/all.min.css">
<link rel="stylesheet" type="text/css" href="/libs/materialize/materialize.min.css">
<link rel="stylesheet" type="text/css" href="/libs/aos/aos.css">
<link rel="stylesheet" type="text/css" href="/libs/animate/animate.min.css">
<link rel="stylesheet" type="text/css" href="/libs/lightGallery/css/lightgallery.min.css">
<link rel="stylesheet" type="text/css" href="/css/matery.css">
<link rel="stylesheet" type="text/css" href="/css/my.css">
<link rel="stylesheet" type="text/css" href="/css/dark.css" media="none" onload="if(media!='all')media='all'">




    <link rel="stylesheet" href="/libs/tocbot/tocbot.css">
    <link rel="stylesheet" href="/css/post.css">




    
        <link rel="stylesheet" type="text/css" href="/css/reward.css">
    



    <script src="/libs/jquery/jquery-3.6.0.min.js"></script>

<meta name="generator" content="Hexo 7.3.0"></head>


<body>
    <header class="navbar-fixed">
    <nav id="headNav" class="bg-color nav-transparent">
        <div id="navContainer" class="nav-wrapper container">
            <div class="brand-logo">
                <a href="/" class="waves-effect waves-light">
                    
                    <img src="/medias/logo.png" class="logo-img" alt="LOGO">
                    
                    <span class="logo-span">小小舒的爪哇天地</span>
                </a>
            </div>
            

<a href="#" data-target="mobile-nav" class="sidenav-trigger button-collapse"><i class="fas fa-bars"></i></a>
<ul class="right nav-menu">
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/" class="waves-effect waves-light">
      
      <i class="fas fa-home" style="zoom: 0.6;"></i>
      
      <span>Index</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/tags" class="waves-effect waves-light">
      
      <i class="fas fa-tags" style="zoom: 0.6;"></i>
      
      <span>Tags</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/categories" class="waves-effect waves-light">
      
      <i class="fas fa-bookmark" style="zoom: 0.6;"></i>
      
      <span>Categories</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/archives" class="waves-effect waves-light">
      
      <i class="fas fa-archive" style="zoom: 0.6;"></i>
      
      <span>Archives</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/about" class="waves-effect waves-light">
      
      <i class="fas fa-user-circle" style="zoom: 0.6;"></i>
      
      <span>About</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/contact" class="waves-effect waves-light">
      
      <i class="fas fa-comments" style="zoom: 0.6;"></i>
      
      <span>Contact</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/friends" class="waves-effect waves-light">
      
      <i class="fas fa-address-book" style="zoom: 0.6;"></i>
      
      <span>Friends</span>
    </a>
    
  </li>
  
  <li>
    <a href="#searchModal" class="modal-trigger waves-effect waves-light">
      <i id="searchIcon" class="fas fa-search" title="Search" style="zoom: 0.85;"></i>
    </a>
  </li>
  <li>
    <a href="javascript:;" class="waves-effect waves-light" onclick="switchNightMode()" title="深色/浅色模式" >
      <i id="sum-moon-icon" class="fas fa-sun" style="zoom: 0.85;"></i>
    </a>
  </li>
</ul>


<div id="mobile-nav" class="side-nav sidenav">

    <div class="mobile-head bg-color">
        
        <img src="/medias/logo.png" class="logo-img circle responsive-img">
        
        <div class="logo-name">小小舒的爪哇天地</div>
        <div class="logo-desc">
            
            Life is coding, I will debug it.
            
        </div>
    </div>

    <ul class="menu-list mobile-menu-list">
        
        <li class="m-nav-item">
	  
		<a href="/" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-home"></i>
			
			Index
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/tags" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-tags"></i>
			
			Tags
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/categories" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-bookmark"></i>
			
			Categories
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/archives" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-archive"></i>
			
			Archives
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/about" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-user-circle"></i>
			
			About
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/contact" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-comments"></i>
			
			Contact
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/friends" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-address-book"></i>
			
			Friends
		</a>
          
        </li>
        
        
        <li><div class="divider"></div></li>
        <li>
            <a href="https://github.com/blinkfox/hexo-theme-matery" class="waves-effect waves-light" target="_blank">
                <i class="fab fa-github-square fa-fw"></i>Fork Me
            </a>
        </li>
        
    </ul>
</div>


        </div>

        
            <style>
    .nav-transparent .github-corner {
        display: none !important;
    }

    .github-corner {
        position: absolute;
        z-index: 10;
        top: 0;
        right: 0;
        border: 0;
        transform: scale(1.1);
    }

    .github-corner svg {
        color: #0f9d58;
        fill: #fff;
        height: 64px;
        width: 64px;
    }

    .github-corner:hover .octo-arm {
        animation: a 0.56s ease-in-out;
    }

    .github-corner .octo-arm {
        animation: none;
    }

    @keyframes a {
        0%,
        to {
            transform: rotate(0);
        }
        20%,
        60% {
            transform: rotate(-25deg);
        }
        40%,
        80% {
            transform: rotate(10deg);
        }
    }
</style>

<a href="https://github.com/blinkfox/hexo-theme-matery" class="github-corner tooltipped hide-on-med-and-down" target="_blank"
   data-tooltip="Fork Me" data-position="left" data-delay="50">
    <svg viewBox="0 0 250 250" aria-hidden="true">
        <path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path>
        <path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2"
              fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path>
        <path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z"
              fill="currentColor" class="octo-body"></path>
    </svg>
</a>
        
    </nav>

</header>

    



<div class="bg-cover pd-header post-cover" style="background-image: url('/medias/featureimages/23.jpg')">
    <div class="container" style="right: 0px;left: 0px;">
        <div class="row">
            <div class="col s12 m12 l12">
                <div class="brand">
                    <h1 class="description center-align post-title">吴恩达机器学习 Course2 week1 神经网络</h1>
                </div>
            </div>
        </div>
    </div>
</div>




<main class="post-container content">

    
    <div class="row">
    <div id="main-content" class="col s12 m12 l9">
        <!-- 文章内容详情 -->
<div id="artDetail">
    <div class="card">
        <div class="card-content article-info">
            <div class="row tag-cate">
                <div class="col s7">
                    
                    <div class="article-tag">
                        
                            <a href="/tags/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/">
                                <span class="chip bg-color">人工智能</span>
                            </a>
                        
                            <a href="/tags/deep-learning/">
                                <span class="chip bg-color">deep learning</span>
                            </a>
                        
                            <a href="/tags/tensorflow/">
                                <span class="chip bg-color">tensorflow</span>
                            </a>
                        
                            <a href="/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/">
                                <span class="chip bg-color">深度学习</span>
                            </a>
                        
                            <a href="/tags/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/">
                                <span class="chip bg-color">神经网络</span>
                            </a>
                        
                    </div>
                    
                </div>
                <div class="col s5 right-align">
                    
                    <div class="post-cate">
                        <i class="fas fa-bookmark fa-fw icon-category"></i>
                        
                            <a href="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/" class="post-category">
                                机器学习
                            </a>
                        
                    </div>
                    
                </div>
            </div>

            <div class="post-info">
                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-minus fa-fw"></i>Publish Date:&nbsp;&nbsp;
                    2025-01-28
                </div>
                

                

                

                

                
            </div>
        </div>
        <hr class="clearfix">

        
        <!-- 是否加载使用自带的 prismjs. -->
        <link rel="stylesheet" href="/libs/prism/prism.min.css">
        

        

        <div class="card-content article-card-content">
            <div id="articleContent">
                <h1 id="吴恩达机器学习-Course2-week1-神经网络"><a href="#吴恩达机器学习-Course2-week1-神经网络" class="headerlink" title="吴恩达机器学习 Course2 week1 神经网络"></a>吴恩达机器学习 Course2 week1 神经网络</h1><h2 id="1-神经网络概述"><a href="#1-神经网络概述" class="headerlink" title="1 神经网络概述"></a>1 神经网络概述</h2><h3 id="1-1-关于Course-2"><a href="#1-1-关于Course-2" class="headerlink" title="1-1 关于Course 2"></a>1-1 关于Course 2</h3><p>Course2会学习“神经网络”(也被称为“深度学习”)、决策树等算法，这些是最强大、最广泛使用的机器学习算法之一。另外也会介绍构建机器学习系统的建议，比如在进行神经网络训练时，是应该收集更多数据？应该购买更强大的GPU来构建更大的神经网络？</p>
<blockquote>
<ol>
<li>Week1：使用别人训练好参数的神经网络，进行预测被称为“<strong>推理</strong>(infrence)”。本周重点介绍“神经网络”的计算原理和调用代码，只“推理”而不涉及“训练”。</li>
<li>week2: 介绍如何训练神经网络。也就是根据标记好的训练集，训练神经网络参数。</li>
<li>Week3：将给出构建机器学习系统的建议</li>
<li>Week4: 介绍“决策树(Decision trees)”，尽管和“神经网络”相比没有那么出名，但这也是一个很强大、广泛使用的机器学习方法。</li>
</ol>
</blockquote>
<h3 id="1-2-神经元和大脑"><a href="#1-2-神经元和大脑" class="headerlink" title="1-2 神经元和大脑"></a>1-2 神经元和大脑</h3><p>神经网络的起源：</p>
<blockquote>
<ul>
<li>1950’s年代：由于人脑或者说生物大脑的比任何“智能”都有着更高的水平，于是“神经网络”最初是想建立模仿大脑的软件。1950’s年代开始这项工作，但是后来就没落了(估计是因为算力不够+也不了解神经元)。</li>
<li>1980’s~1990’s早期：由于被应用于手写数字识别等应用中，“神经网络”再度被重视。比如识别邮政编码从而分拣信件、识别手写支票中的美元数字等。但是在1990’s晚期再度失宠。</li>
<li>大约2005年~至今：开始复苏，并被重新命名成“深度学习”。从那以后，“神经网络”在一个有一个领域取得了空前进展。<ol>
<li>第一个由于“神经网络”而取得巨大进步的领域是“语音识别(speech recognition)”，<a target="_blank" rel="noopener" href="https://baike.baidu.com/item/%E9%82%93%E5%8A%9B/20811707">邓力</a> 和 <a target="_blank" rel="noopener" href="https://baike.baidu.com/item/%E6%9D%B0%E5%BC%97%E9%87%8C%C2%B7%E8%BE%9B%E9%A1%BF/23419046">杰弗里·辛顿</a> 等人将现代深度学习算法应用到该领域。</li>
<li>然后就是“计算机视觉(cpmputer vision)”，2012年是ImageNet的推出对计算机视觉产生了重要的影响。</li>
<li>接下来几年进入了“文本处理”或“自然语言处理(NLP)”。</li>
<li>如今：神经网络被应用于方方面面，比如气候变化、医学成像、在线广告推广等。基本上很多推荐机制都是使用神经网络来完成。</li>
</ol>
</li>
</ul>
<p>注：“神经网络”被重新命名成“深度学习”，一方面是因为听起来更高大上，另一方面是因为人类根本不了解“神经元”的工作方式，现代的深度学习也不想再深究以前的生物学动机，只想从工程的角度构建更有效的算法，所以逐渐舍弃“神经网络”这种叫法。</p>
</blockquote>
<p>在几十年前，当“神经网络(neural networks)”被首次提出时，其最初的动机模仿(mimic)人脑或生物大脑学习和思考的方式，编写一个可以自动运行的软件。虽然如今的“神经网络”，也被称为“人工神经网络(artifical neural network)”，其原理已经和我们大脑实际上的工作方式相去甚远，但是我们还是会看到一些最初的“生物学动机(biological motivations)”。</p>
<p><strong>神经元简化结构</strong></p>
<p>人脑由几百亿个神经元组成，现在我们来看看神经元的简化结构。如下左图，单个神经元有很多“树突(dendrite)”作为输入端，通过“轴突(axon)”输出，该输出可以继续连接一个或多个神经元。于是，单个神经元可以看成“多个输入到单个输出的映射”。在下右图中，使用“蓝色小圈”表示单个神经元，于是“神经网络”就是由多个神经元组成的，能够将输入映射到输出的系统。</p>
<p><img src="http://img-md-js.linjsblog.top/img/202501122058213.png" alt="img"></p>
<p>注意这里的介绍只是一个简单的类比，实际上人脑的工作方式更加复杂和精妙，人类目前并不能完全了解人脑的工作方式。基本上每隔几年，神经科学家都会在人脑工作方式领域有根本性的突破。但即使是这些及其简化的神经元模型，也可以训练出很强大的深度学习模型。事实上，从事神经网络研究的人已经从寻找生物学动机渐渐远离，大家只是想从“工程原理”的角度来构建更有效的算法，所以不要太把自己局限在这些生物学动机当中。当然，时不时的想想神经元真正的工作方式也很有趣。 <strong>神经网络兴起的真正原因</strong></p>
<p>既然神经网络已经在几十年前就提出了，为什么最近几年才开始真正的发展呢？简单来说，是因为存储和算力的发展。在下图中，横轴表示对某问题所拥有的数据量，纵轴表示应用于该问题的“学习算法”的性能或精度。过去几十年间，随着互联网的发展，横轴上的数据在不断增长，若使用传统的机器学习算法，比如“线性回归”或“逻辑回归”，算法性能已经趋于上限。也就是说，传统的AI算法不能有效的利用现在庞大的数据。而得益于算力的发展，主要是GPU的发展，可以部署越来越大规模的神经网络模型，算法精度也相应的取得了质的提升。也就是说，得益于现在的存储和算力，神经网络才取得长足的发展。 <img src="http://img-md-js.linjsblog.top/img/202501122058543.png" alt="img"></p>
<h3 id="1-3-需求预测"><a href="#1-3-需求预测" class="headerlink" title="1-3 需求预测"></a>1-3 需求预测</h3><p>  为了说明神经网络的形成原理，本节先从一个小例子——“需求预测”问题开始：</p>
<blockquote>
<p>“<strong>需求预测</strong>(Demand Predication)”问题：预测某产品是否为畅销产品。</p>
<ul>
<li>输入特征：价格、运费、市场营销、材质等。</li>
<li>输出：二元输出，是否为畅销产品(0&#x2F;1)。</li>
</ul>
</blockquote>
<p>我们先只考虑“价格”这一个特征，对于这种二元分类问题，仿照“逻辑回归”，我们仍然可以使用Sigmoid函数来拟合单个神经元的模型函数。于是该神经元模型，输入价格特征 x ，输出当前衬衫为畅销产品的概率 f ( x )（在神经网络中被称为“激活值” a ）。这个小逻辑回归算法可以认为是非常简化的单个神经元模型，如下图所示：</p>
<p><img src="http://img-md-js.linjsblog.top/img/202501122244770.png" alt="img"></p>
<blockquote>
<p>**<em>a</em>**表示“激活(activation)”。来自于神经科学中的术语，表示当前神经元向下一神经元发送的电脉冲强度(0~1之间的数字)。</p>
</blockquote>
<p>下面进一步改进模型，首先是将输入特征扩展为四个(价格、运费、市场营销、材质)，但若将这几个特征直接和最后一个神经元相连，这就回到之前的“逻辑回归”了，我们不能这么做。所以我们我们不妨添加一层“消费者因素”，我们定义消费者是否购买一件产品可能取决于三个因素(“心理预期价格”、“认可度”、“产品质量”)，这三种因素又取决于不同的输入特征(如下图黄色连线所示)。于是，将“输入特征”、“消费者因素”、“输出概率”这三者使用不同层的神经元连接在一起，每个神经元都是一个小型的逻辑回归算法，便将“单神经元模型”扩展为“神经网络模型”：</p>
<p><img src="http://img-md-js.linjsblog.top/img/202501122245072.png" alt="img"></p>
<blockquote>
<ul>
<li>输入层(input layer)：包含全部的特征，一般表示为 “输入特征向量“ $\vec{x}$</li>
<li>隐藏层(hidden layer)：对输入层的$\vec{x}$进行映射，得到”激活向量“ $\vec{a}$ ,发送给输出层</li>
<li>输出层(output layer)：根据 $\vec{a}$ 计算出最终的预测结果，也就是成为畅销产品的概率。</li>
</ul>
<p>注1：具有相似输入特征的神经元会被分组为同一“层”(layer)。 注2：除了输入层，所有隐藏层+输出层&#x3D;神经网络总层数。比如上图就是两层神经网络。</p>
</blockquote>
<p>上述就是整个神经网络的形成原理。但注意到上述我们手动规定了“隐藏层”的神经元数量、每个神经元与输入特征的关系。要是遇到庞大且复杂的神经网络，显然都靠手动规定几乎不可能！所以<strong>实际构建神经网络时，只需要设定隐藏层数量、以及每个隐藏层的神经元数量，其他的对应关系等无需规定，神经网络模型都可以自行学习</strong>（Week2介绍）。这也解释了，之所以称之为“隐藏层”，是因为我们一般只知 道数据集$(\vec{X},\vec{Y})$ ,而不会像上述一样预先设置好“消费者因素”，也就是说，我们一开始并不知道“隐藏层”间的神经元之间的对应关系。</p>
<p> 最后要说的一点是，上述只是具有单个隐藏层的神经网络模型，下面是具有多个隐藏层的，某些文献中也被称为“多层感知器(multilayer perceptron)”：</p>
<p><img src="http://img-md-js.linjsblog.top/img/202501122252246.png" alt="img"></p>
<h3 id="1-4-举例-图像感知"><a href="#1-4-举例-图像感知" class="headerlink" title="1-4 举例-图像感知"></a>1-4 举例-图像感知</h3><p>那“隐藏层”具体都在做什么事情呢？我们使用计算机视觉中的“人脸识别”来举例，现在有一个已经训练好的神经网络模型，下面来看看隐藏层在做什么工作（注意不同的神经网络可能不同）：</p>
<p>“<strong>人脸识别</strong>”(face recognition)问题：识别图片中的人脸是谁。</p>
<ul>
<li>输入特征：100x100的图片。</li>
<li>输出：图片中的人脸，是某个人的概率。</li>
</ul>
<p><img src="http://img-md-js.linjsblog.top/img/202501122316506.png" alt="img"></p>
<blockquote>
<ul>
<li><p>隐藏层1：识别一些很小的边缘或线，比如不同的神经元识别不同方向的小边缘或线。</p>
</li>
<li><p>隐藏层2：将小边缘组合在一起，识别面部的某个区域，比如鼻子、眼睛、嘴等。</p>
</li>
<li><p>隐藏层3：将上述面部区域再组合，检测到整张人脸，然后再根据脸型对比和目标人脸的相似程度。</p>
</li>
</ul>
<p>总结：越靠后的隐藏层，识别区域越大。 注：“汽车检测”的隐藏层功能也相似。</p>
</blockquote>
<p>可以看到，神经网络如此强大！我们预先并没有告诉这些隐藏层需要做什么，但仅仅通过学习输入的数据，神经网络便可以自动生成这些不同隐藏层的特征检测器。本周晚些时候还会介绍如何构建“手写数字识别”的神经网络。</p>
<h2 id="2-神经网络"><a href="#2-神经网络" class="headerlink" title="2 神经网络"></a>2 神经网络</h2><h3 id="2-1-神经网络中的网络层"><a href="#2-1-神经网络中的网络层" class="headerlink" title="2-1 神经网络中的网络层"></a>2-1 神经网络中的网络层</h3><blockquote>
<p>术语</p>
<p>上标方括号 $^{[l]}$: 表示第 l l_l_ 层神经网络</p>
<p>$w_{j}^{[l]},b_{j}^{[l]}$ : 第 $l$ 层神经网络的第 j 个参数</p>
<p>$ \vec{a} ^{[l]}$：第 $l$ 层神经网络输出的向量形式的“激活值”。</p>
<p>$a^{[l]}$ : 第 $l$ 层神经网络输出的单个“激活值”，一般是最后一层的“输出层”的输出。</p>
<p>$\vec{a}^{[0]}$ : 一般等价于输入特征$\vec{x}$, 该表达式是为了与隐藏层、输入层统一形式</p>
<p>g(.) : 默认表示Sigmoid函数，是神经网络“激活函数”的其中一种</p>
<p>按照惯例，神经网络的层数 &#x3D; 所有隐藏层 + 输出层。比如，两层神经网络就是只包含一个隐藏层。</p>
</blockquote>
<p><img src="http://img-md-js.linjsblog.top/img/202501261942413.png" alt="img"></p>
<p>图1</p>
<p><img src="http://img-md-js.linjsblog.top/img/202501261942941.png" alt="img"></p>
<p>图2</p>
<p><img src="http://img-md-js.linjsblog.top/img/202501261942103.png" alt="img"></p>
<p>图3</p>
<blockquote>
<p>输入层(layer0)：给出特征向量 $\vec{x}$ ，比如令 $\vec{x}$⃗ &#x3D; [ 197 , 184 , 136 , 214 ] 。 隐藏层(layer1)：如图1，包括三个神经元，每个神经元使用Sigmoid函数，并且都有各自的参数$\vec{w}<em>{j}^{[l]},{b}</em>{j}^{[l]}$ ,j&#x3D;1,2,3; 假设这三个神经元的计算结果组成当前层的激活向量$\vec{a}^{[1]}&#x3D;[0.3,0.7,0.2]$.</p>
<p>输出层(layer2)：如图2，只有单个神经元，利用参数 $\vec{w}<em>{1}^{[2]},{b}</em>{1}^{[2]}$ 和输入的 $\vec{a}^{[1]} 计算出 \vec{a}^{[2]} &#x3D; 0.84$</p>
<p>判决：对于图3，对输出层的结果进行二进制判决，阈值可设置为0.5。这一步并不是必要的。</p>
</blockquote>
<h3 id="2-2-更复杂的神经网络"><a href="#2-2-更复杂的神经网络" class="headerlink" title="2-2 更复杂的神经网络"></a>2-2 更复杂的神经网络</h3><p><img src="http://img-md-js.linjsblog.top/img/202501262133006.png" alt="image-20250126213318916"></p>
<p>显然上图中，每一层都有一个输入向量，经过当前层所有神经元的得到输出向量，传递给下一层。将符号整理得更加清晰一些，于是第 $l$ 层神经网络的第 $j$ 个神经元的输出可以写成：</p>
<p>$$<br>a_{j}^{[l]} &#x3D; g(\vec{w}<em>{j}^{[l]} \cdot \vec{a}^{[l-1]} + b</em>{j}^{[l]})<br>$$</p>
<p>将输入特征写为 $\vec{x} &#x3D; \vec{a}^{[0]}$ 上式就具有通用性。</p>
<h3 id="2-3-神经网络前向传播"><a href="#2-3-神经网络前向传播" class="headerlink" title="2-3 神经网络前向传播"></a>2-3 神经网络前向传播</h3><p>“手写数字识别”问题：简洁起见，只识别手写数字0和1。</p>
<p>输入特征：8x8的灰度图(灰度级0~255)，0表示黑色，255表示白色。于是输入特征 $\vec{x}$的长度为64。 输出：二元分类，输入图片是数字1的概率。</p>
<p>假设我们使用三层神经网络，隐藏层1有25个神经元、隐藏层2有15个神经元，每层神经元的计算公式如下图所示，</p>
<p><img src="http://img-md-js.linjsblog.top/img/202501262357286.png" alt="img"></p>
<p>将上述表达式合并，于是第 $ l $ 层神经网络的输出为(矩阵格式)：</p>
<p>$\vec{A}^{[l]} &#x3D; g(\vec{W}^{[l]} \vec{A}^{[l-1]} + \vec{B}^{[l]})$</p>
<p>解释：</p>
<ul>
<li>约定当前层为 $l$ ，且当前层总共有 $M$个神经元。</li>
<li>$\vec{A}^{[l-1]}$ 或 $\vec{a}^{[l-1]}$ : N_1 的二维矩阵(列向量)， 上一层的激活向量，假设其长度为_ N*。</li>
<li>$\vec{W}^{[l]}$: M*N二维矩阵，当前层所有的 $\vec{w}<em>{j}^{[l]}$ 参数。第j行表示第j个神经元的参数$\vec{w}</em>{j}^{[l]}$（行向量）</li>
<li>$\vec{B}^{[l]}$: M*1 的二维矩阵(M维列向量), 当前层所有的$b_{j}^{[l]}$ 参数</li>
<li>$\vec{A}^{[l]}$ : M*1 当前层输出的激活向量。</li>
</ul>
<p>注：$或者反过来 1_N 行向量\vec{A}^{[l-1]}, 和 N_M 的 \vec{W}^{[l]} , 输出1*M的行向量$ 这样编程更方便</p>
<p>此时</p>
<p><img src="http://img-md-js.linjsblog.top/img/202501271144041.png" alt="image-20250127114401930"></p>
<p>定义每层的输出为行向量，主要为了编程方便，$\vec{x}$ 一般都会按行输入。</p>
<p>$\vec{A}^{[3]}$只有一个元素，所以可以认为是一个值。</p>
<h2 id="3-TensorFlow-简介"><a href="#3-TensorFlow-简介" class="headerlink" title="3 TensorFlow 简介"></a>3 TensorFlow 简介</h2><h3 id="3-1-配置tensorflow"><a href="#3-1-配置tensorflow" class="headerlink" title="3-1 配置tensorflow"></a>3-1 配置tensorflow</h3><p>TensorFlow是实现深度学习算法的框架之一，但目前国内最常使用PyTorch，但不用担心，两者代码几乎完全相同。</p>
<p>安装TensorFlow 的CPU版本</p>
<pre class="line-numbers language-none"><code class="language-none"># 安装时会自动选择和Python环境匹配的版本
pip install tensorflow<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre>

<p>安装TensorFlow-GPU版本，硬件最好为AMD显卡(N卡)。然后，配置好CUDA</p>
<pre class="line-numbers language-none"><code class="language-none"># 安装时会自动选择和Python环境匹配的版本
pip install tensorflow-gpu<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre>

<p>注：从 TensorFlow 2.1 开始，<code>tensorflow-gpu</code> 包已经被合并到 <code>tensorflow</code> 包中。你只需要安装 <code>tensorflow</code>，它会自动检测并利用 GPU。</p>
<h3 id="3-2-TensorFlow中的张量"><a href="#3-2-TensorFlow中的张量" class="headerlink" title="3-2 TensorFlow中的张量"></a>3-2 TensorFlow中的张量</h3><p>在Python中，大家最常使用“NumPy库”来完成线性代数的运算；而涉及到神经网络的计算，则通常交给Tensorflow完成。因为历史遗留问题，两者的数据格式并不统一。</p>
<p>如下所示，NumPy中行向量、列向量、数字列表的区别主要在于方括号的层数：</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token comment"># 最外层方括号：表示定义矩阵</span>
<span class="token comment"># 里层的方括号：表示一行数据</span>
x <span class="token operator">=</span> np<span class="token punctuation">.</span>array<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">200</span><span class="token punctuation">,</span> <span class="token number">17</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span> <span class="token comment"># 行向量，1x2的二维数组</span>

x <span class="token operator">=</span> np<span class="token punctuation">.</span>array<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">200</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
              <span class="token punctuation">[</span><span class="token number">17</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span>      <span class="token comment"># 列向量，2x1的二维数组</span>

x <span class="token operator">=</span> np<span class="token punctuation">.</span>array<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">200</span><span class="token punctuation">,</span> <span class="token number">17</span><span class="token punctuation">]</span><span class="token punctuation">)</span>   <span class="token comment"># 数字列表，无法参与矩阵运算</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<p>而TensorFlow旨在处理非常大的数据集，所以传入其内部的数据都会转化成“<strong>张量</strong>(tensor)”，这样可以使其内部计算更加高效。TensorFlow的二维张量和NumPy的二维数组，存储格式并不相同。</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token comment"># 直接打印</span>
tf<span class="token punctuation">.</span>Tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">0.3</span><span class="token punctuation">,</span><span class="token number">0.7</span><span class="token punctuation">,</span>    <span class="token number">0.2</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">,</span> shape<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">,</span> dtype<span class="token operator">=</span>float32<span class="token punctuation">)</span>

<span class="token comment"># 转换成NumPy格式再打印</span>
a1<span class="token punctuation">.</span>numpy<span class="token punctuation">(</span><span class="token punctuation">)</span>
array<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">0.3</span> <span class="token number">0.7</span> <span class="token number">0.2</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">,</span> dtype<span class="token operator">=</span>float32<span class="token punctuation">)</span> <span class="token comment"># 不显示矩阵大小</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<p>所以建议：</p>
<ol>
<li>传入数据：要传递给TensorFlow的数据，都使用两层方括号定义成矩阵(二维张量)。</li>
<li>读出数据：TensorFlow处理完毕后，可以先将其转换成NumPy的数据格式，再调用NumPy的方法进行后续处理。</li>
</ol>
<h2 id="4-代码实现"><a href="#4-代码实现" class="headerlink" title="4 代码实现"></a>4 代码实现</h2><h3 id="4-1-如何用代码实现推理-烤咖啡豆"><a href="#4-1-如何用代码实现推理-烤咖啡豆" class="headerlink" title="4-1 如何用代码实现推理-烤咖啡豆"></a>4-1 如何用代码实现推理-烤咖啡豆</h3><p>“烤咖啡豆”问题：判断咖啡豆是否烤得恰到好处。</p>
<ul>
<li>输入特征：“烘焙温度”、“烘焙时间”。</li>
<li>输出：二元分类，咖啡豆是否烤好了，红叉表示烤好了、蓝圈表示没烤好。</li>
</ul>
<p><img src="http://img-md-js.linjsblog.top/img/202501271300179.png" alt="img"></p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python">x <span class="token operator">=</span> np<span class="token punctuation">.</span>array<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">200.0</span><span class="token punctuation">,</span><span class="token number">17.0</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span> <span class="token comment"># 输入特征</span>
layer_1 <span class="token operator">=</span> Dense<span class="token punctuation">(</span>units <span class="token operator">=</span> <span class="token number">3</span><span class="token punctuation">,</span>activation <span class="token operator">=</span> <span class="token string">'sigmoid'</span><span class="token punctuation">)</span> <span class="token comment">#定义隐藏层  dense 是神经网络单层(layer)的另一个名称</span>
a_1 <span class="token operator">=</span> layer_1<span class="token punctuation">(</span>x<span class="token punctuation">)</span> <span class="token comment"># 计算激活向量</span>

<span class="token comment"># 输出层</span>
layer_2 <span class="token operator">=</span> Dense<span class="token punctuation">(</span>units<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> activation<span class="token operator">=</span><span class="token string">'sigmoid'</span><span class="token punctuation">)</span>  <span class="token comment"># 定义输出层</span>
a2 <span class="token operator">=</span> layer_2<span class="token punctuation">(</span>a1<span class="token punctuation">)</span>                                <span class="token comment"># 计算输出值</span>

<span class="token comment"># 判决</span>
<span class="token keyword">if</span> a2 <span class="token operator">>=</span> <span class="token number">0.5</span><span class="token punctuation">:</span>
    yhat <span class="token operator">=</span> <span class="token number">1</span>
<span class="token keyword">else</span><span class="token punctuation">:</span>
    yhat <span class="token operator">=</span> <span class="token number">0</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<p><img src="http://img-md-js.linjsblog.top/img/202501271326983.png" alt="image-20250127132651855"></p>
<h3 id="4-2-搭建一个神经网络"><a href="#4-2-搭建一个神经网络" class="headerlink" title="4-2 搭建一个神经网络"></a>4-2 搭建一个神经网络</h3><p>我们希望它采用第一层和第二层并将它们串在一起形成一个神经网络，而不是手动获取数据将其传到第一层然后从一层获取激活并将其传递到第二层</p>
<p><img src="http://img-md-js.linjsblog.top/img/202501271558579.png" alt="image-20250127155850470"></p>
<p>sequential framework 可以为你做很多工作。</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token comment"># 烤咖啡豆-代码整合</span>
<span class="token comment"># 定义训练集</span>
x <span class="token operator">=</span> np<span class="token punctuation">.</span>array<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">200.0</span><span class="token punctuation">,</span> <span class="token number">17.0</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
              <span class="token punctuation">[</span><span class="token number">120.0</span><span class="token punctuation">,</span> <span class="token number">5.0</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
              <span class="token punctuation">[</span><span class="token number">425.0</span><span class="token punctuation">,</span> <span class="token number">20.0</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
              <span class="token punctuation">[</span><span class="token number">212.0</span><span class="token punctuation">,</span> <span class="token number">18.0</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
y <span class="token operator">=</span> np<span class="token punctuation">.</span>array<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">0</span><span class="token punctuation">,</span><span class="token number">0</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span>

<span class="token comment"># 定义神经网络</span>
layer_1 <span class="token operator">=</span> Dense<span class="token punctuation">(</span>units<span class="token operator">=</span><span class="token number">3</span><span class="token punctuation">,</span> activation<span class="token operator">=</span><span class="token string">'sigmoid'</span><span class="token punctuation">)</span>  <span class="token comment"># 定义隐藏层</span>
layer_2 <span class="token operator">=</span> Dense<span class="token punctuation">(</span>units<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> activation<span class="token operator">=</span><span class="token string">'sigmoid'</span><span class="token punctuation">)</span>  <span class="token comment"># 定义输出层</span>
model <span class="token operator">=</span> Sequential<span class="token punctuation">(</span><span class="token punctuation">[</span>layer_1<span class="token punctuation">,</span> layer_2<span class="token punctuation">]</span><span class="token punctuation">)</span>          <span class="token comment"># 连接两层</span>

<span class="token comment"># 编译并训练网络</span>
model<span class="token punctuation">.</span><span class="token builtin">compile</span><span class="token punctuation">(</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">)</span>    <span class="token comment"># 编译整个神经网络，下周具体介绍</span>
model<span class="token punctuation">.</span>fit<span class="token punctuation">(</span>x<span class="token punctuation">,</span>y<span class="token punctuation">)</span>        <span class="token comment"># 训练数据集，下周具体介绍</span>

<span class="token comment"># 预测并判决</span>
a_last <span class="token operator">=</span> model<span class="token punctuation">.</span>predict<span class="token punctuation">(</span>x_new<span class="token punctuation">)</span>
<span class="token keyword">if</span> a_last <span class="token operator">>=</span> <span class="token number">0.5</span><span class="token punctuation">:</span>
    yhat <span class="token operator">=</span> <span class="token number">1</span>
<span class="token keyword">else</span><span class="token punctuation">:</span>
    yhat <span class="token operator">=</span> <span class="token number">0</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<h3 id="4-3-神经网络的内部实现"><a href="#4-3-神经网络的内部实现" class="headerlink" title="4-3 神经网络的内部实现"></a>4-3 神经网络的内部实现</h3><p>直接调用TensorFlow库代码即可实现神经网络的构建，虽然直接调用很有效率，但是了解其背后的工作原理还是非常重要的</p>
<p>还是刚才的“烤咖啡豆”模型。</p>
<ol>
<li><p>对每个神经元进行硬编码，如下图“烤咖啡豆”问题-每个神经元的计算</p>
<p><img src="http://img-md-js.linjsblog.top/img/202501271633637.png"></p>
</li>
<li><p>将每一层神经元的计算封装成一个 ，<code>dense(a_in,w,b,g)</code>函数，再将所有层封装成一个网络 <code>sequential()</code>。</p>
<p><img src="http://img-md-js.linjsblog.top/img/202501271657118.png" alt="img"></p>
<blockquote>
<p>shape会输出一个形状的列表[row,columns],然后对列表索引[0]就是行数，[1]就是列数，W.shape[0] –&gt; 代表行数 W.shape[1] –&gt;代表列数</p>
<p>在这个例子中，我们需要输出三个激活值，所以这只是将 a_out 初始化为[0,0,0]，一个由三个零组成的数组。</p>
<p>W[ : , j]二维数组切片，取第j列的每一行，也就是把第j列全取了</p>
</blockquote>
</li>
</ol>
<h3 id="4-4-通过矩阵乘法优化dense函数"><a href="#4-4-通过矩阵乘法优化dense函数" class="headerlink" title="4-4 通过矩阵乘法优化dense函数"></a>4-4 通过矩阵乘法优化dense函数</h3><p><img src="http://img-md-js.linjsblog.top/img/202501271712345.png" alt="img"></p>
<ul>
<li>左侧还有一些“数字列表”，右侧全是二维数组。也就是进行了“向量化”。</li>
<li><code>np.matmul()</code>函数是矩阵乘法函数，具体的矩阵乘法过程见“线性代数”知识</li>
<li><code>Z = np.matmul(AT,W)</code>等价于 <code>Z = AT @ W</code>，也就是说 <code>@</code>就是NumPy中的矩阵乘法符号</li>
</ul>
<p>神经网络的规模之所以可以越来越大，得益于“矢量化”，这保证神经网络可以使用矩阵运算高效地部署。这是因为并行计算硬件，比如GPU或者强大的CPU，非常擅长做非常大的矩阵运算。</p>
<h3 id="4-5-代码实现-手写数字识别"><a href="#4-5-代码实现-手写数字识别" class="headerlink" title="4-5 代码实现-手写数字识别"></a>4-5 代码实现-手写数字识别</h3><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token comment"># 手写数字识别-代码整合</span>
<span class="token comment"># 定义训练集</span>
x <span class="token operator">=</span> np<span class="token punctuation">.</span>array<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">0.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">245</span><span class="token punctuation">,</span> <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">17</span><span class="token punctuation">]</span><span class="token punctuation">,</span>   <span class="token comment"># 1的训练图片</span>
              <span class="token punctuation">[</span><span class="token number">0.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">200</span><span class="token punctuation">,</span> <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">184</span><span class="token punctuation">]</span><span class="token punctuation">)</span>  <span class="token comment"># 0的训练图片</span>
y <span class="token operator">=</span> np<span class="token punctuation">.</span>array<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span>

<span class="token comment"># 定义神经网络</span>
layer_1 <span class="token operator">=</span> Dense<span class="token punctuation">(</span>units<span class="token operator">=</span><span class="token number">25</span><span class="token punctuation">,</span> activation<span class="token operator">=</span><span class="token string">'sigmoid'</span><span class="token punctuation">)</span>  <span class="token comment"># 定义隐藏层1</span>
layer_2 <span class="token operator">=</span> Dense<span class="token punctuation">(</span>units<span class="token operator">=</span><span class="token number">15</span><span class="token punctuation">,</span> activation<span class="token operator">=</span><span class="token string">'sigmoid'</span><span class="token punctuation">)</span>  <span class="token comment"># 定义隐藏层2</span>
layer_3 <span class="token operator">=</span> Dense<span class="token punctuation">(</span>units<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span>  activation<span class="token operator">=</span><span class="token string">'sigmoid'</span><span class="token punctuation">)</span>  <span class="token comment"># 定义输出层</span>
model <span class="token operator">=</span> Sequential<span class="token punctuation">(</span><span class="token punctuation">[</span>layer_1<span class="token punctuation">,</span> layer_2<span class="token punctuation">,</span> layer_3<span class="token punctuation">]</span><span class="token punctuation">)</span>  <span class="token comment"># 连接三层</span>
<span class="token comment">###################也可以将上述四行合并####################</span>
<span class="token comment"># model = Sequential([</span>
<span class="token comment">#         Dense(units=25, activation='sigmoid'),  # 隐藏层1</span>
<span class="token comment">#         Dense(units=15, activation='sigmoid'),  # 隐藏层2</span>
<span class="token comment">#         Dense(units=1,  activation='sigmoid')]) # 输出层</span>
<span class="token comment">#########################################################</span>

<span class="token comment"># 编译并训练网络</span>
model<span class="token punctuation">.</span><span class="token builtin">compile</span><span class="token punctuation">(</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">)</span>  <span class="token comment"># 编译整个神经网络，下周具体介绍</span>
model<span class="token punctuation">.</span>fit<span class="token punctuation">(</span>x<span class="token punctuation">,</span>y<span class="token punctuation">)</span>      <span class="token comment"># 训练数据集，下周具体介绍</span>

<span class="token comment"># 预测并判决</span>
a_last <span class="token operator">=</span> model<span class="token punctuation">.</span>predict<span class="token punctuation">(</span>x_new<span class="token punctuation">)</span>
<span class="token keyword">if</span> a_last <span class="token operator">>=</span> <span class="token number">0.5</span><span class="token punctuation">:</span>
    yhat <span class="token operator">=</span> 1python
<span class="token keyword">else</span><span class="token punctuation">:</span>
    yhat <span class="token operator">=</span> <span class="token number">0</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<p>详细代码见option lab C2_W1_Assignment</p>
<h2 id="5-强人工智能"><a href="#5-强人工智能" class="headerlink" title="5 强人工智能"></a>5 强人工智能</h2><p>谈谈“AGI(Artifical General Intelligence, 通用人工智能)”。老师一直梦想着构建一个和人一样聪明的AI系统，这也是全世界人工智能领域的愿景，但是前路漫漫，不知道几十年、上百年能否实现。不过，如今AGI的目标是构建一个“和人一样聪明的AI”，这让人兴奋但同时又有很多不切实际的炒作，比如《终结者》系列电影中的“天网”要灭绝人类，这引起一部分人对于AI的恐慌。但其实AI主要包括两方面完全不一样的内容：</p>
<ol>
<li>ANI(Artifical Narrow Intelligence, 狭义人工智能)：一次只做一件事的AI。比如智能扬声器、自动驾驶汽车、网络搜索、用于特定农场或工厂的AI等。过去几年间，ANI取得了巨大的进步并带动了巨大的社会经济效益，常见于生活的方方面面。</li>
<li>AGI(Artifical General Intelligence, 通用人工智能)：可以像人类一样做任何事的AI。</li>
</ol>
<p>并且，即使从“模拟人脑”的角度来看，要想实现真正的AGI依旧非常困难，主要有两个原因：</p>
<ol>
<li>目前的神经元模型非常简单，实际上人脑神经元的工作机制要复杂得多。</li>
<li>从医学角度来说，我们也不完全了解人脑是如何工作的。</li>
</ol>
<p>总结：老师认为仅通过“模拟大脑神经元”的方式，就实现了AGI，是非常困难的。 注：这大概也是现在改称“深度学习”的原因。</p>
<p>  虽然不用恐慌，但是我们就没有实现AGI的可能了吗？也不是，比如下面的几个实验就显示出，人类大脑的某个区域，即使是非常小的一块区域，都具有惊人的适应性、可塑性：</p>
<p><img src="http://img-md-js.linjsblog.top/img/202501271802740.png" alt="img"></p>
<ol>
<li>使用“听觉皮层”看：将大脑的“听觉皮层”和原有的神经切断，再连接上图像信号，那么一段时间后，该区域皮层就“学会了看”。用于感受触觉的“体感皮层”也是同理。</li>
<li>使用舌头看。头上安装摄像机，并将其拍摄到的灰度值映射到舌头上的电压矩阵。给盲人带上学习一段时间，盲人就可以“看见”物体。</li>
<li>人体声纳。训练人类发出“哒哒声”(类似于弹舌)，并观察声音是如何在环境中反射的。经过一段时间的训练，有些人可以实现“回声定位”。</li>
<li>方向感知。带上一个腰带，该腰带中指向北方的蜂鸣器会缓慢震动，一段时间后，就会一直知道北方在哪里(带着腰带)，而不是再去首先感受蜂鸣器振动。</li>
<li>植入第三只眼。一段时间后，青蛙就会熟练使用第三只眼。</li>
</ol>
<p>这一系列实验表明，大脑的许多区域，其功能仅取决于输入的数据，换言之，这些区域都有一个“通用算法”。如果我们能了解这一小块区域的算法，我们就能用计算机进行模拟，进而可能会创造出AGI。但显然这是一条很困难的道路，因为我们不确定大脑是不是就是一堆算法，就算是，我们也不知道这个算法是什么，但希望通过我们的努力在某一个可以接近这个“算法”。</p>
<p>  实现AGI的想法真的很迷人，我们应当理性看待，而不应过度炒作。但如果同学们觉得这些伦理问题困扰到了自己，就不用想这么多，也不用想什么AGI，只要知道神经网络是一个很有帮助的工具也很不错。</p>

                
            </div>
            <hr/>

            

    <div class="reprint" id="reprint-statement">
        
            <div class="reprint__author">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-user">
                        Author:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="/about" rel="external nofollow noreferrer">qwq小小舒</a>
                </span>
            </div>
            <div class="reprint__type">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-link">
                        Link:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="https://js6288.github.io/2025/01/28/%E5%90%B4%E6%81%A9%E8%BE%BE%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0-course2-week1-%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/">https://js6288.github.io/2025/01/28/%E5%90%B4%E6%81%A9%E8%BE%BE%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0-course2-week1-%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/</a>
                </span>
            </div>
            <div class="reprint__notice">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-copyright">
                        Reprint policy:
                    </i>
                </span>
                <span class="reprint-info">
                    All articles in this blog are used except for special statements
                    <a href="https://creativecommons.org/licenses/by/4.0/deed.zh" rel="external nofollow noreferrer" target="_blank">CC BY 4.0</a>
                    reprint policy. If reproduced, please indicate source
                    <a href="/about" target="_blank">qwq小小舒</a>
                    !
                </span>
            </div>
        
    </div>

    <script async defer>
      document.addEventListener("copy", function (e) {
        let toastHTML = '<span>Copied successfully, please follow the reprint policy of this article</span><button class="btn-flat toast-action" onclick="navToReprintStatement()" style="font-size: smaller">more</a>';
        M.toast({html: toastHTML})
      });

      function navToReprintStatement() {
        $("html, body").animate({scrollTop: $("#reprint-statement").offset().top - 80}, 800);
      }
    </script>



            <div class="tag_share" style="display: block;">
                <div class="post-meta__tag-list" style="display: inline-block;">
                    
                        <div class="article-tag">
                            
                                <a href="/tags/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/">
                                    <span class="chip bg-color">人工智能</span>
                                </a>
                            
                                <a href="/tags/deep-learning/">
                                    <span class="chip bg-color">deep learning</span>
                                </a>
                            
                                <a href="/tags/tensorflow/">
                                    <span class="chip bg-color">tensorflow</span>
                                </a>
                            
                                <a href="/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/">
                                    <span class="chip bg-color">深度学习</span>
                                </a>
                            
                                <a href="/tags/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/">
                                    <span class="chip bg-color">神经网络</span>
                                </a>
                            
                        </div>
                    
                </div>
                <div class="post_share" style="zoom: 80%; width: fit-content; display: inline-block; float: right; margin: -0.15rem 0;">
                    <link rel="stylesheet" type="text/css" href="/libs/share/css/share.min.css">
<div id="article-share">

    
    <div class="social-share" data-sites="twitter,facebook,google,qq,qzone,wechat,weibo,douban,linkedin" data-wechat-qrcode-helper="<p>微信扫一扫即可分享！</p>"></div>
    <script src="/libs/share/js/social-share.min.js"></script>
    

    

</div>

                </div>
            </div>
            
                <div id="reward">
    <a href="#rewardModal" class="reward-link modal-trigger btn-floating btn-medium waves-effect waves-light red">赏</a>

    <!-- Modal Structure -->
    <div id="rewardModal" class="modal">
        <div class="modal-content">
            <a class="close modal-close"><i class="fas fa-times"></i></a>
            <h4 class="reward-title">你的赏识是我前进的动力</h4>
            <div class="reward-content">
                <div class="reward-tabs">
                    <ul class="tabs row">
                        <li class="tab col s6 alipay-tab waves-effect waves-light"><a href="#alipay">支付宝</a></li>
                        <li class="tab col s6 wechat-tab waves-effect waves-light"><a href="#wechat">微 信</a></li>
                    </ul>
                    <div id="alipay">
                        <img src="/medias/reward/alipay.jpg" class="reward-img" alt="支付宝打赏二维码">
                    </div>
                    <div id="wechat">
                        <img src="/medias/reward/wechat.png" class="reward-img" alt="微信打赏二维码">
                    </div>
                </div>
            </div>
        </div>
    </div>
</div>

<script>
    $(function () {
        $('.tabs').tabs();
    });
</script>

            
        </div>
    </div>

    

    

    

    

    

    

    

    

    

<article id="prenext-posts" class="prev-next articles">
    <div class="row article-row">
        
        <div class="article col s12 m6" data-aos="fade-up" data-aos="fade-up">
            <div class="article-badge left-badge text-color">
                <i class="far fa-dot-circle"></i>&nbsp;Current
            </div>
            <div class="card">
                <a href="/2025/01/28/%E5%90%B4%E6%81%A9%E8%BE%BE%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0-course2-week1-%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/">
                    <div class="card-image">
                        
                        
                        <img src="/medias/featureimages/23.jpg" class="responsive-img" alt="吴恩达机器学习 Course2 week1 神经网络">
                        
                        <span class="card-title">吴恩达机器学习 Course2 week1 神经网络</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            
                        
                    </div>
                    <div class="publish-info">
                            <span class="publish-date">
                                <i class="far fa-clock fa-fw icon-date"></i>2025-01-28
                            </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/" class="post-category">
                                    机器学习
                                </a>
                            
                            
                        </span>
                    </div>
                </div>

                
                <div class="card-action article-tags">
                    
                    <a href="/tags/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/">
                        <span class="chip bg-color">人工智能</span>
                    </a>
                    
                    <a href="/tags/deep-learning/">
                        <span class="chip bg-color">deep learning</span>
                    </a>
                    
                    <a href="/tags/tensorflow/">
                        <span class="chip bg-color">tensorflow</span>
                    </a>
                    
                    <a href="/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/">
                        <span class="chip bg-color">深度学习</span>
                    </a>
                    
                    <a href="/tags/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/">
                        <span class="chip bg-color">神经网络</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge right-badge text-color">
                Next&nbsp;<i class="fas fa-chevron-right"></i>
            </div>
            <div class="card">
                <a href="/2024/12/30/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%90%B4%E6%81%A9%E8%BE%BE%E7%AC%94%E8%AE%B0-week3/">
                    <div class="card-image">
                        
                        
                        <img src="/medias/featureimages/20.jpg" class="responsive-img" alt="机器学习吴恩达笔记 week3">
                        
                        <span class="card-title">机器学习吴恩达笔记 week3</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            
                        
                    </div>
                    <div class="publish-info">
                            <span class="publish-date">
                                <i class="far fa-clock fa-fw icon-date"></i>2024-12-30
                            </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/" class="post-category">
                                    学习笔记
                                </a>
                            
                            <a href="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/" class="post-category">
                                    机器学习
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/tags/machine-learning/">
                        <span class="chip bg-color">machine learning</span>
                    </a>
                    
                    <a href="/tags/%E6%95%B0%E5%AD%A6/">
                        <span class="chip bg-color">数学</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
    </div>
</article>

</div>



<!-- 代码块功能依赖 -->
<script type="text/javascript" src="/libs/codeBlock/codeBlockFuction.js"></script>


  <!-- 是否加载使用自带的 prismjs. -->
  <script type="text/javascript" src="/libs/prism/prism.min.js"></script>


<!-- 代码语言 -->

<script type="text/javascript" src="/libs/codeBlock/codeLang.js"></script>


<!-- 代码块复制 -->

<script type="text/javascript" src="/libs/codeBlock/codeCopy.js"></script>


<!-- 代码块收缩 -->

<script type="text/javascript" src="/libs/codeBlock/codeShrink.js"></script>



    </div>
    <div id="toc-aside" class="expanded col l3 hide-on-med-and-down">
        <div class="toc-widget card" style="background-color: white;">
            <div class="toc-title"><i class="far fa-list-alt"></i>&nbsp;&nbsp;TOC</div>
            <div id="toc-content"></div>
        </div>
    </div>
</div>

<!-- TOC 悬浮按钮. -->

<div id="floating-toc-btn" class="hide-on-med-and-down">
    <a class="btn-floating btn-large bg-color">
        <i class="fas fa-list-ul"></i>
    </a>
</div>


<script src="/libs/tocbot/tocbot.min.js"></script>
<script>
    $(function () {
        tocbot.init({
            tocSelector: '#toc-content',
            contentSelector: '#articleContent',
            headingsOffset: -($(window).height() * 0.4 - 45),
            collapseDepth: Number('0'),
            headingSelector: 'h2, h3, h4'
        });

        // Set scroll toc fixed.
        let tocHeight = parseInt($(window).height() * 0.4 - 64);
        let $tocWidget = $('.toc-widget');
        $(window).scroll(function () {
            let scroll = $(window).scrollTop();
            /* add post toc fixed. */
            if (scroll > tocHeight) {
                $tocWidget.addClass('toc-fixed');
            } else {
                $tocWidget.removeClass('toc-fixed');
            }
        });

        
        /* 修复文章卡片 div 的宽度. */
        let fixPostCardWidth = function (srcId, targetId) {
            let srcDiv = $('#' + srcId);
            if (srcDiv.length === 0) {
                return;
            }

            let w = srcDiv.width();
            if (w >= 450) {
                w = w + 21;
            } else if (w >= 350 && w < 450) {
                w = w + 18;
            } else if (w >= 300 && w < 350) {
                w = w + 16;
            } else {
                w = w + 14;
            }
            $('#' + targetId).width(w);
        };

        // 切换TOC目录展开收缩的相关操作.
        const expandedClass = 'expanded';
        let $tocAside = $('#toc-aside');
        let $mainContent = $('#main-content');
        $('#floating-toc-btn .btn-floating').click(function () {
            if ($tocAside.hasClass(expandedClass)) {
                $tocAside.removeClass(expandedClass).hide();
                $mainContent.removeClass('l9');
            } else {
                $tocAside.addClass(expandedClass).show();
                $mainContent.addClass('l9');
            }
            fixPostCardWidth('artDetail', 'prenext-posts');
        });
        
    });
</script>

    

</main>


<script src="https://cdn.bootcss.com/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
<script>
    MathJax.Hub.Config({
        tex2jax: {inlineMath: [['$', '$'], ['\\(', '\\)']]}
    });
</script>



    <footer class="page-footer bg-color">
    
        <link rel="stylesheet" href="/libs/aplayer/APlayer.min.css">
<style>
    .aplayer .aplayer-lrc p {
        
        display: none;
        
        font-size: 12px;
        font-weight: 700;
        line-height: 16px !important;
    }

    .aplayer .aplayer-lrc p.aplayer-lrc-current {
        
        display: none;
        
        font-size: 15px;
        color: #42b983;
    }

    
    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body {
        left: -66px !important;
    }

    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body:hover {
        left: 0px !important;
    }

    
</style>
<div class="">
    
    <div class="row">
        <meting-js class="col l8 offset-l2 m10 offset-m1 s12"
                   server="netease"
                   type="playlist"
                   id="503838841"
                   fixed='true'
                   autoplay='false'
                   theme='#42b983'
                   loop='all'
                   order='random'
                   preload='auto'
                   volume='0.7'
                   list-folded='true'
        >
        </meting-js>
    </div>
</div>

<script src="/libs/aplayer/APlayer.min.js"></script>
<script src="/libs/aplayer/Meting.min.js"></script>

    

    <div class="container row center-align"
         style="margin-bottom: 0px !important;">
        <div class="col s12 m8 l8 copy-right">
            Copyright&nbsp;&copy;
            
                <span id="year">2019-2025</span>
            
            <a href="/about" target="_blank">qwq小小舒</a>
            |&nbsp;Powered by&nbsp;<a href="https://hexo.io/" target="_blank">Hexo</a>
            |&nbsp;Theme&nbsp;<a href="https://github.com/blinkfox/hexo-theme-matery" target="_blank">Matery</a>
            
            <br>
            
            
            
                
            
            
                <span id="busuanzi_container_site_pv">
                &nbsp;|&nbsp;<i class="far fa-eye"></i>&nbsp;Total visits:&nbsp;
                    <span id="busuanzi_value_site_pv" class="white-color"></span>
            </span>
            
            
                <span id="busuanzi_container_site_uv">
                &nbsp;|&nbsp;<i class="fas fa-users"></i>&nbsp;Total visitors:&nbsp;
                    <span id="busuanzi_value_site_uv" class="white-color"></span>
            </span>
            
            <br>

            <!-- 运行天数提醒. -->
            
            <br>
            
        </div>
        <div class="col s12 m4 l4 social-link social-statis">
    <a href="https://github.com/blinkfox" class="tooltipped" target="_blank" data-tooltip="访问我的GitHub" data-position="top" data-delay="50">
        <i class="fab fa-github"></i>
    </a>



    <a href="mailto:1181062873@qq.com" class="tooltipped" target="_blank" data-tooltip="邮件联系我" data-position="top" data-delay="50">
        <i class="fas fa-envelope-open"></i>
    </a>







    <a href="tencent://AddContact/?fromId=50&fromSubId=1&subcmd=all&uin=1181062873" class="tooltipped" target="_blank" data-tooltip="QQ联系我: 1181062873" data-position="top" data-delay="50">
        <i class="fab fa-qq"></i>
    </a>







    <a href="/atom.xml" class="tooltipped" target="_blank" data-tooltip="RSS 订阅" data-position="top" data-delay="50">
        <i class="fas fa-rss"></i>
    </a>

</div>
    </div>
</footer>

<div class="progress-bar"></div>


    <!-- 搜索遮罩框 -->
<div id="searchModal" class="modal">
    <div class="modal-content">
        <div class="search-header">
            <span class="title"><i class="fas fa-search"></i>&nbsp;&nbsp;Search</span>
            <input type="search" id="searchInput" name="s" placeholder="Please enter a search keyword"
                   class="search-input">
        </div>
        <div id="searchResult"></div>
    </div>
</div>

<script type="text/javascript">
$(function () {
    var searchFunc = function (path, search_id, content_id) {
        'use strict';
        $.ajax({
            url: path,
            dataType: "xml",
            success: function (xmlResponse) {
                // get the contents from search data
                var datas = $("entry", xmlResponse).map(function () {
                    return {
                        title: $("title", this).text(),
                        content: $("content", this).text(),
                        url: $("url", this).text()
                    };
                }).get();
                var $input = document.getElementById(search_id);
                var $resultContent = document.getElementById(content_id);
                $input.addEventListener('input', function () {
                    var str = '<ul class=\"search-result-list\">';
                    var keywords = this.value.trim().toLowerCase().split(/[\s\-]+/);
                    $resultContent.innerHTML = "";
                    if (this.value.trim().length <= 0) {
                        return;
                    }
                    // perform local searching
                    datas.forEach(function (data) {
                        var isMatch = true;
                        var data_title = data.title.trim().toLowerCase();
                        var data_content = data.content.trim().replace(/<[^>]+>/g, "").toLowerCase();
                        var data_url = data.url;
                        data_url = data_url.indexOf('/') === 0 ? data.url : '/' + data_url;
                        var index_title = -1;
                        var index_content = -1;
                        var first_occur = -1;
                        // only match artiles with not empty titles and contents
                        if (data_title !== '' && data_content !== '') {
                            keywords.forEach(function (keyword, i) {
                                index_title = data_title.indexOf(keyword);
                                index_content = data_content.indexOf(keyword);
                                if (index_title < 0 && index_content < 0) {
                                    isMatch = false;
                                } else {
                                    if (index_content < 0) {
                                        index_content = 0;
                                    }
                                    if (i === 0) {
                                        first_occur = index_content;
                                    }
                                }
                            });
                        }
                        // show search results
                        if (isMatch) {
                            str += "<li><a href='" + data_url + "' class='search-result-title'>" + data_title + "</a>";
                            var content = data.content.trim().replace(/<[^>]+>/g, "");
                            if (first_occur >= 0) {
                                // cut out 100 characters
                                var start = first_occur - 20;
                                var end = first_occur + 80;
                                if (start < 0) {
                                    start = 0;
                                }
                                if (start === 0) {
                                    end = 100;
                                }
                                if (end > content.length) {
                                    end = content.length;
                                }
                                var match_content = content.substr(start, end);
                                // highlight all keywords
                                keywords.forEach(function (keyword) {
                                    var regS = new RegExp(keyword, "gi");
                                    match_content = match_content.replace(regS, "<em class=\"search-keyword\">" + keyword + "</em>");
                                });

                                str += "<p class=\"search-result\">" + match_content + "...</p>"
                            }
                            str += "</li>";
                        }
                    });
                    str += "</ul>";
                    $resultContent.innerHTML = str;
                });
            }
        });
    };

    searchFunc('/search.xml', 'searchInput', 'searchResult');
});
</script>

    <!-- 白天和黑夜主题 -->
<div class="stars-con">
    <div id="stars"></div>
    <div id="stars2"></div>
    <div id="stars3"></div>  
</div>

<script>
    function switchNightMode() {
        $('<div class="Cuteen_DarkSky"><div class="Cuteen_DarkPlanet"></div></div>').appendTo($('body')),
        setTimeout(function () {
            $('body').hasClass('DarkMode') 
            ? ($('body').removeClass('DarkMode'), localStorage.setItem('isDark', '0'), $('#sum-moon-icon').removeClass("fa-sun").addClass('fa-moon')) 
            : ($('body').addClass('DarkMode'), localStorage.setItem('isDark', '1'), $('#sum-moon-icon').addClass("fa-sun").removeClass('fa-moon')),
            
            setTimeout(function () {
            $('.Cuteen_DarkSky').fadeOut(1e3, function () {
                $(this).remove()
            })
            }, 2e3)
        })
    }
</script>

    <!-- 回到顶部按钮 -->
<div id="backTop" class="top-scroll">
    <a class="btn-floating btn-large waves-effect waves-light" href="#!">
        <i class="fas fa-arrow-up"></i>
    </a>
</div>


    <script src="/libs/materialize/materialize.min.js"></script>
    <script src="/libs/masonry/masonry.pkgd.min.js"></script>
    <script src="/libs/aos/aos.js"></script>
    <script src="/libs/scrollprogress/scrollProgress.min.js"></script>
    <script src="/libs/lightGallery/js/lightgallery-all.min.js"></script>
    <script src="/js/matery.js"></script>

    

    
    
    

    <!-- 雪花特效 -->
    

    <!-- 鼠标星星特效 -->
    

     
        <script src="https://ssl.captcha.qq.com/TCaptcha.js"></script>
        <script src="/libs/others/TencentCaptcha.js"></script>
        <button id="TencentCaptcha" data-appid="xxxxxxxxxx" data-cbfn="callback" type="button" hidden></button>
    

    <!-- Baidu Analytics -->

    <!-- Baidu Push -->

<script>
    (function () {
        var bp = document.createElement('script');
        var curProtocol = window.location.protocol.split(':')[0];
        if (curProtocol === 'https') {
            bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';
        } else {
            bp.src = 'http://push.zhanzhang.baidu.com/push.js';
        }
        var s = document.getElementsByTagName("script")[0];
        s.parentNode.insertBefore(bp, s);
    })();
</script>

    
    <script src="/libs/others/clicklove.js" async="async"></script>
    
    
    <script async src="/libs/others/busuanzi.pure.mini.js"></script>
    

    

    

    <!--腾讯兔小巢-->
    
    

    

    

    
    <script src="/libs/instantpage/instantpage.js" type="module"></script>
    

</body>

</html>
